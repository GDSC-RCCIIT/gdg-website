{
  "hackathons": [
    {
      "basicInformation": {
        "id": "1",
        "hackathonTitle": "Tech for Good Hackathon",
        "description": "A 48-hour hackathon focused on leveraging technology to address pressing challenges in the healthcare sector. Participants will explore innovative approaches to improve patient care, streamline medical processes, and enhance accessibility in healthcare. Ideal for innovators, developers, and healthcare professionals.",
        "dateAndTime": {
          "start": "2024-11-01T09:00:00Z",
          "end": "2024-11-03T17:00:00Z"
        },
        "duration": "48 hours",
        "location": "Online",
        "theme": "Technology for Social Impact",
        "eligibility": "Open to students, professionals, and developers worldwide. Minimum age: 18"
      },
      "registrationAndParticipation": {
        "registrationLink": "https://github.com/GDSC-RCCIIT/gdg-website",
        "teamSize": "1-5 members",
        "registrationDeadline": "2024-10-28",
        "participationFee": "Free"
      },
      "prizesAndPerks": {
        "prizePool": "$10,000",
        "prizeCategories": [
          "Best Overall Project",
          "Most Innovative Solution",
          "Best Use of Technology"
        ],
        "perks": [
          "Mentorship sessions",
          "Access to premium tools",
          "Networking opportunities"
        ]
      },
      "rulesAndGuidelines": {
        "codeOfConduct": "Participants are expected to be respectful and inclusive, adhering to ethical guidelines.",
        "judgingCriteria": [
          "Innovation",
          "Technical Implementation",
          "Feasibility",
          "Social Impact"
        ],
        "projectSubmissionGuidelines": {
          "format": "GitHub repository or .zip file",
          "fileTypes": ["code files", "presentation"],
          "deadline": "2024-11-03T17:00:00Z"
        }
      },
      "additionalInformation": {
        "organizers": [
          {
            "name": "GDSC RCCIIT",
            "contact": "contact@gdscrcciit.com"
          }
        ],
        "sponsors": [
          {
            "name": "TechCorp",
            "logo": "Img1"
          },
          {
            "name": "InnovateX",
            "logo": "Img1"
          }
        ],
        "faqs": [
          {
            "question": "Who can participate?",
            "answer": "Anyone aged 18 or older with an interest in tech for social good."
          },
          {
            "question": "Is prior experience required?",
            "answer": "No, beginners are welcome!"
          }
        ],
        "socialMediaHandles": {
          "twitter": "https://twitter.com/GDSC_RCCIIT",
          "instagram": "https://instagram.com/GDSC_RCCIIT"
        },
        "contactInformation": "support@gdscrcciit.com"
      },
      "visualElements": {
        "bannerImage": "Img1",
        "logo": "Img1",
        "socialMediaSharingButtons": "enabled"
      }
    },
    {
      "basicInformation": {
        "id": "2",
        "hackathonTitle": "Green Innovators Challenge",
        "description": "A 36-hour virtual hackathon aimed at developing innovative AI solutions to improve accessibility for individuals with disabilities. This event is open to developers, designers, and enthusiasts focused on creating inclusive technologies that enhance independence and quality of life for users.",
        "dateAndTime": {
          "start": "2024-12-05T08:00:00Z",
          "end": "2024-12-07T20:00:00Z"
        },
        "duration": "72 hours",
        "location": "Hybrid (New York City & Online)",
        "theme": "Sustainable Tech Solutions",
        "eligibility": "Open to all; teams encouraged."
      },
      "registrationAndParticipation": {
        "registrationLink": "https://github.com/GDSC-RCCIIT/gdg-website",
        "teamSize": "2-6 members",
        "registrationDeadline": "2024-02-30",
        "participationFee": "$25"
      },
      "prizesAndPerks": {
        "prizePool": "$15,000",
        "prizeCategories": [
          "Best Green Technology",
          "Most Feasible Solution",
          "People's Choice Award"
        ],
        "perks": [
          "Free eco-friendly swag",
          "Access to sustainability mentors",
          "Networking with green tech companies"
        ]
      },
      "rulesAndGuidelines": {
        "codeOfConduct": "Respectful and inclusive participation is mandatory.",
        "judgingCriteria": [
          "Innovation",
          "Sustainability",
          "Technical Feasibility",
          "Presentation"
        ],
        "projectSubmissionGuidelines": {
          "format": "GitHub link or PDF presentation",
          "fileTypes": ["pdf", "code files"],
          "deadline": "2024-12-07T20:00:00Z"
        }
      },
      "additionalInformation": {
        "organizers": [
          {
            "name": "EcoTech Collective",
            "contact": "contact@ecotechcollective.com"
          }
        ],
        "sponsors": [
          {
            "name": "GreenWorks",
            "logo": "Img1"
          },
          {
            "name": "EcoFuture",
            "logo": "Img1"
          }
        ],
        "faqs": [
          {
            "question": "Can teams participate remotely?",
            "answer": "Yes, online participation is supported."
          }
        ],
        "socialMediaHandles": {
          "facebook": "https://facebook.com/EcoTechCollective"
        },
        "contactInformation": "support@ecotechcollective.com"
      },
      "visualElements": {
        "bannerImage": "Img1",
        "logo": "Img1",
        "socialMediaSharingButtons": "enabled"
      }
    },
    {
      "basicInformation": {
        "id": "3",
        "hackathonTitle": "FinTech Future Hackathon",
        "description": "FinTech Future Hackathon is a 36-hour sprint where participants are invited to develop the next wave of financial technology solutions. This event focuses on creating secure, efficient, and user-friendly financial applications that cater to modern digital banking, investment, and finance needs.",
        "dateAndTime": {
          "start": "2024-11-20T10:00:00Z",
          "end": "2024-11-22T18:00:00Z"
        },
        "duration": "48 hours",
        "location": "Virtual",
        "theme": "Innovating Financial Technology",
        "eligibility": "University students and recent graduates in finance or tech fields."
      },
      "registrationAndParticipation": {
        "registrationLink": "https://github.com/GDSC-RCCIIT/gdg-website",
        "teamSize": "3-5 members",
        "registrationDeadline": "2024-11-15",
        "participationFee": "Free"
      },
      "prizesAndPerks": {
        "prizePool": "$20,000",
        "prizeCategories": [
          "Best FinTech Solution",
          "Best UX/UI Design",
          "Best Use of Blockchain"
        ],
        "perks": [
          "Workshops on FinTech trends",
          "Mentorship with industry experts",
          "Certificate of participation"
        ]
      },
      "rulesAndGuidelines": {
        "codeOfConduct": "Professional and respectful conduct required.",
        "judgingCriteria": [
          "Innovation",
          "User Experience",
          "Market Potential",
          "Technical Implementation"
        ],
        "projectSubmissionGuidelines": {
          "format": "GitHub repository",
          "fileTypes": ["code files", "presentation"],
          "deadline": "2024-11-22T18:00:00Z"
        }
      },
      "additionalInformation": {
        "organizers": [
          {
            "name": "Global FinTech Hub",
            "contact": "contact@globalfintechhub.com"
          }
        ],
        "sponsors": [
          {
            "name": "BankTech Inc.",
            "logo": "Img1"
          },
          {
            "name": "CryptoNet",
            "logo": "Img1"
          }
        ],
        "faqs": [
          {
            "question": "Are there specific tech stacks required?",
            "answer": "No, participants are free to choose any tech stack."
          }
        ],
        "socialMediaHandles": {
          "linkedin": "https://linkedin.com/company/GlobalFinTechHub"
        },
        "contactInformation": "info@globalfintechhub.com"
      },
      "visualElements": {
        "bannerImage": "Img1",
        "logo": "Img1",
        "socialMediaSharingButtons": "enabled"
      }
    },
    {
      "basicInformation": {
        "id": "4",
        "hackathonTitle": "HealthTech Revolution",
        "description": "HealthTech Revolution is an intensive, innovation-driven hackathon focused on transforming healthcare through technology. Over 48 hours, participants will tackle real-world healthcare challenges by developing solutions that enhance patient care, streamline operations, and improve overall healthcare access.",
        "dateAndTime": {
          "start": "2024-10-29T12:00:00Z",
          "end": "2024-10-31T18:00:00Z"
        },
        "duration": "2 days",
        "location": "Hybrid (San Francisco & Online)",
        "theme": "Health and Wellness Solutions",
        "eligibility": "Open to healthcare professionals, students, and tech enthusiasts."
      },
      "registrationAndParticipation": {
        "registrationLink": "https://github.com/GDSC-RCCIIT/gdg-website",
        "teamSize": "1-4 members",
        "registrationDeadline": "2024-10-25",
        "participationFee": "$30"
      },
      "prizesAndPerks": {
        "prizePool": "$25,000",
        "prizeCategories": [
          "Best Health Solution",
          "Best Patient Experience",
          "Most Scalable Product"
        ],
        "perks": [
          "Workshops on health tech trends",
          "Networking with healthcare experts",
          "HealthTech merchandise"
        ]
      },
      "rulesAndGuidelines": {
        "codeOfConduct": "Professional conduct and collaboration are expected.",
        "judgingCriteria": [
          "Innovation",
          "Impact",
          "Technical Feasibility",
          "Scalability"
        ],
        "projectSubmissionGuidelines": {
          "format": "PDF presentation with demo link",
          "fileTypes": ["pdf", "code files"],
          "deadline": "2024-10-31T18:00:00Z"
        }
      },
      "additionalInformation": {
        "organizers": [
          {
            "name": "MedTech Innovators",
            "contact": "contact@medtechinnovators.com"
          }
        ],
        "sponsors": [
          {
            "name": "HealthFirst",
            "logo": "Img1"
          },
          {
            "name": "WellTech",
            "logo": "Img1"
          }
        ],
        "faqs": [
          {
            "question": "Do I need a healthcare background to participate?",
            "answer": "No, the hackathon is open to all backgrounds."
          }
        ],
        "socialMediaHandles": {
          "instagram": "https://instagram.com/MedTechInnovators"
        },
        "contactInformation": "support@medtechinnovators.com"
      },
      "visualElements": {
        "bannerImage": "Img1",
        "logo": "Img1",
        "socialMediaSharingButtons": "enabled"
      }
    },
    {
      "basicInformation": {
        "id": "5",
        "hackathonTitle": "AI for Accessibility Hackathon",
        "description": "Develop an AI-powered news aggregator that curates the latest tech news from multiple sources and personalizes recommendations. Ideal for participants interested in machine learning and AI.",
        "dateAndTime": {
          "start": "2024-11-15T08:00:00Z",
          "end": "2024-11-16T20:00:00Z"
        },
        "duration": "36 hours",
        "location": "Online",
        "theme": "Artificial Intelligence for Accessibility",
        "eligibility": "Open to developers, designers, and students interested in AI for accessibility."
      },
      "registrationAndParticipation": {
        "registrationLink": "https://github.com/GDSC-RCCIIT/gdg-website",
        "teamSize": "2-6 members",
        "registrationDeadline": "2024-11-10",
        "participationFee": "Free"
      },
      "prizesAndPerks": {
        "prizePool": "$12,000",
        "prizeCategories": [
          "Best AI Solution",
          "Best Accessibility Tool",
          "Most Inclusive Design"
        ],
        "perks": [
          "Mentorship from AI experts",
          "AI tool credits",
          "Networking with tech companies"
        ]
      },
      "rulesAndGuidelines": {
        "codeOfConduct": "Inclusive and respectful behavior is required.",
        "judgingCriteria": [
          "Innovation",
          "Accessibility Impact",
          "Technical Implementation",
          "User Experience"
        ],
        "projectSubmissionGuidelines": {
          "format": "GitHub repository or zip file",
          "fileTypes": ["code files", "presentation"],
          "deadline": "2024-11-16T20:00:00Z"
        }
      },
      "additionalInformation": {
        "organizers": [
          {
            "name": "Inclusive Tech Foundation",
            "contact": "info@inclusivetech.org"
          }
        ],
        "sponsors": [
          {
            "name": "TechForAll",
            "logo": "Img1"
          },
          {
            "name": "AIConnect",
            "logo": "Img1"
          }
        ],
        "faqs": [
          {
            "question": "Do I need experience in AI to participate?",
            "answer": "No, participants of all experience levels are welcome."
          }
        ],
        "socialMediaHandles": {
          "twitter": "https://twitter.com/InclusiveTech"
        },
        "contactInformation": "support@inclusivetech.org"
      },
      "visualElements": {
        "bannerImage": "/Img1",
        "logo": "/Img1",
        "socialMediaSharingButtons": "enabled"
      }
    }
  ],
  "projects": [
    {
      "id": "1",
      "projectTitle": "AI-Powered Chatbot Development",
      "projectOverview": "This project aims to develop an AI-powered chatbot to enhance customer service efficiency and improve user experience on our platform.",
      "projectStartDate": "2024-01-15",
      "projectEndDate": "2024-06-30",
      "projectManager": {
        "name": "John Doe",
        "contact": "john.doe@example.com"
      },
      "projectTeamMembers": [
        {
          "name": "Alice Smith",
          "role": "Lead Developer",
          "responsibilities": "Overseeing the development of chatbot features.",
          "linkedin": "https://www.linkedin.com/in/alicesmith",
          "designatedWork": "Backend development and API integration."
        },
        {
          "name": "Bob Johnson",
          "role": "UX/UI Designer",
          "responsibilities": "Designing user interfaces and user experience flows.",
          "linkedin": "https://www.linkedin.com/in/bobjohnson",
          "designatedWork": "Creating wireframes and prototypes."
        },
        {
          "name": "Sarah Lee",
          "role": "Data Scientist",
          "responsibilities": "Building and training machine learning models.",
          "linkedin": "https://www.linkedin.com/in/sarahlee",
          "designatedWork": "Data analysis and model optimization."
        }
      ],
      "primaryGoals": [
        "Improve customer satisfaction by reducing response time.",
        "Increase user engagement through interactive features."
      ],
      "specificObjectives": [
        "Integrate natural language processing capabilities.",
        "Launch a beta version for user feedback by April 2024.",
        "Train the chatbot using historical customer interaction data."
      ],
      "totalProjectBudget": 150000,
      "milestoneSchedule": [
        {
          "milestone": "Project Kickoff",
          "targetCompletionDate": "2024-01-20"
        },
        {
          "milestone": "Completion of Design Phase",
          "targetCompletionDate": "2024-03-15"
        },
        {
          "milestone": "Beta Launch",
          "targetCompletionDate": "2024-04-30"
        },
        {
          "milestone": "Final Launch",
          "targetCompletionDate": "2024-06-30"
        }
      ],
      "projectPlan": "https://example.com/project-plan-document.pdf",
      "currentStatus": {
        "completedTasks": [
          "Project kickoff meeting held.",
          "Design phase initiated."
        ],
        "ongoingTasks": [
          "Developing backend functionalities.",
          "Conducting user research."
        ],
        "upcomingMilestones": [
          "Completion of Design Phase on 2024-03-15",
          "Beta Launch on 2024-04-30"
        ]
      },
      "youtubeLink": "https://www.youtube.com/watch?v=dQw4w9WgXcQ"
    },
    {
      "id": "2",
      "projectTitle": "Website Redesign",
      "projectOverview": "A complete overhaul of the company website to improve navigation, aesthetics, and functionality.",
      "projectStartDate": "2024-02-01",
      "projectEndDate": "2024-05-15",
      "projectManager": {
        "name": "Emily Carter",
        "contact": "emily.carter@example.com"
      },
      "projectTeamMembers": [
        {
          "name": "David Brown",
          "role": "Project Coordinator",
          "responsibilities": "Coordinating project activities and communications.",
          "linkedin": "https://www.linkedin.com/in/davidbrown",
          "designatedWork": "Stakeholder communication and project tracking."
        },
        {
          "name": "Sophia Wilson",
          "role": "Web Developer",
          "responsibilities": "Implementing the new website design.",
          "linkedin": "https://www.linkedin.com/in/sophiawilson",
          "designatedWork": "Frontend development and testing."
        },
        {
          "name": "Michael Johnson",
          "role": "Content Strategist",
          "responsibilities": "Creating and optimizing content for the new site.",
          "linkedin": "https://www.linkedin.com/in/michaeljohnson",
          "designatedWork": "Content creation and SEO optimization."
        }
      ],
      "primaryGoals": [
        "Enhance user experience and engagement.",
        "Increase site traffic by 30% within six months of launch."
      ],
      "specificObjectives": [
        "Redesign website layout and visuals by March 2024.",
        "Implement responsive design features.",
        "Launch the new site with optimized content."
      ],
      "totalProjectBudget": 80000,
      "milestoneSchedule": [
        {
          "milestone": "Design Approval",
          "targetCompletionDate": "2024-03-01"
        },
        {
          "milestone": "Development Completion",
          "targetCompletionDate": "2024-04-15"
        },
        {
          "milestone": "Site Launch",
          "targetCompletionDate": "2024-05-15"
        }
      ],
      "projectPlan": "https://example.com/website-redesign-plan.pdf",
      "currentStatus": {
        "completedTasks": [
          "Initial design mockups created.",
          "Stakeholder feedback received."
        ],
        "ongoingTasks": [
          "Developing website backend functionalities.",
          "Writing and optimizing new content."
        ],
        "upcomingMilestones": [
          "Design Approval on 2024-03-01",
          "Development Completion on 2024-04-15"
        ]
      },
      "youtubeLink": "https://www.youtube.com/watch?v=5aA7i_8v1h8"
    },
    {
      "id": "3",
      "projectTitle": "Mobile App Development for E-Commerce",
      "projectOverview": "Development of a mobile application to enhance customer shopping experience and streamline order processes.",
      "projectStartDate": "2024-03-10",
      "projectEndDate": "2024-09-20",
      "projectManager": {
        "name": "Lucas Green",
        "contact": "lucas.green@example.com"
      },
      "projectTeamMembers": [
        {
          "name": "Laura Martinez",
          "role": "Product Owner",
          "responsibilities": "Defining product vision and ensuring alignment with business goals.",
          "linkedin": "https://www.linkedin.com/in/lauramartinez",
          "designatedWork": "Managing product backlog and prioritizing features."
        },
        {
          "name": "James Lee",
          "role": "Mobile Developer",
          "responsibilities": "Developing mobile application features.",
          "linkedin": "https://www.linkedin.com/in/jameslee",
          "designatedWork": "iOS and Android development."
        },
        {
          "name": "Olivia Taylor",
          "role": "QA Tester",
          "responsibilities": "Testing the application for bugs and performance issues.",
          "linkedin": "https://www.linkedin.com/in/oliviataylor",
          "designatedWork": "Conducting usability testing."
        }
      ],
      "primaryGoals": [
        "Launch a user-friendly e-commerce app.",
        "Increase mobile sales by 40% within the first quarter."
      ],
      "specificObjectives": [
        "Develop app wireframes and mockups by April 2024.",
        "Integrate payment gateways by July 2024.",
        "Launch app on App Store and Google Play by September 2024."
      ],
      "totalProjectBudget": 120000,
      "milestoneSchedule": [
        {
          "milestone": "Wireframes Completion",
          "targetCompletionDate": "2024-04-30"
        },
        {
          "milestone": "Payment Integration",
          "targetCompletionDate": "2024-07-15"
        },
        {
          "milestone": "App Launch",
          "targetCompletionDate": "2024-09-20"
        }
      ],
      "projectPlan": "https://example.com/mobile-app-plan.pdf",
      "currentStatus": {
        "completedTasks": [
          "User research completed.",
          "Initial wireframes created."
        ],
        "ongoingTasks": [
          "Developing core app functionalities.",
          "Setting up payment gateway."
        ],
        "upcomingMilestones": [
          "Wireframes Completion on 2024-04-30",
          "Payment Integration on 2024-07-15"
        ]
      },
      "youtubeLink": "https://www.youtube.com/watch?v=3N1Cg7nM3Bg"
    }
  ],
  "events": [
    {
      "id": "1",
      "title": "Tech for Good Hackathon",
      "description": "A 48-hour hackathon focused on leveraging technology to address challenges in healthcare.",
      "date": {
        "start": "2024-11-01T09:00:00Z",
        "end": "2024-11-03T17:00:00Z"
      },
      "location": "Online",
      "status": "finished",
      "prizes": [
        {
          "category": "Best Overall Project",
          "amount": "$3,000"
        },
        {
          "category": "Most Innovative Solution",
          "amount": "$2,000"
        }
      ],
      "organizers": ["GDSC RCCIIT"],
      "participants": 150
    },
    {
      "id": "2",
      "title": "Web Development Bootcamp",
      "description": "A three-day intensive bootcamp to learn web development from scratch.",
      "date": {
        "start": "2024-09-10T09:00:00Z",
        "end": "2024-09-12T17:00:00Z"
      },
      "location": "RCCIIT Campus",
      "status": "finished",
      "organizers": ["GDSC RCCIIT"],
      "participants": 50
    },
    {
      "id": "3",
      "title": "AI & ML Workshop",
      "description": "A hands-on workshop on artificial intelligence and machine learning concepts.",
      "date": {
        "start": "2024-10-15T09:00:00Z",
        "end": "2024-10-30T17:00:00Z"
      },
      "location": "Online",
      "status": "ongoing",
      "organizers": ["GDSC RCCIIT"],
      "participants": 80
    },
    {
      "id": "4",
      "title": "Cloud Computing Seminar",
      "description": "An interactive seminar discussing cloud computing trends and best practices.",
      "date": {
        "start": "2024-11-05T14:00:00Z",
        "end": "2024-11-05T16:00:00Z"
      },
      "location": "Online",
      "status": "upcoming",
      "registrationLink": "https://example.com/register-cloud-seminar",
      "organizers": ["GDSC RCCIIT"],
      "participants": 0
    },
    {
      "id": "5",
      "title": "Mobile App Development Workshop",
      "description": "Learn to build mobile applications using Flutter in this hands-on workshop.",
      "date": {
        "start": "2024-11-15T10:00:00Z",
        "end": "2024-11-17T17:00:00Z"
      },
      "location": "RCCIIT Campus",
      "status": "upcoming",
      "registrationLink": "https://example.com/register-mobile-workshop",
      "organizers": ["GDSC RCCIIT"],
      "participants": 0
    }
  ],
  "careers": [
    {
      "id": "1",
      "title": "Senior Staff Software Developer, Kubernetes",
      "description": "Work on building the future of Kubernetes with our cloud-native team.",
      "location": "Remote eligible",
      "office": "Kirkland, WA, USA; +5 more",
      "image": "/spot1.jpg",
      "details": "As a Senior Software Developer, you will be part of a team responsible for the future development of Kubernetes...",
      "company": "Google",
      "minimum_qualifications": {
        "degree": "Bachelor's degree in Computer Science or related field.",
        "experience": [
          "5+ years of experience in software development.",
          "Strong background in Kubernetes and cloud technologies."
        ]
      },
      "preferred_qualifications": {
        "coding_experience": "Experience with Go, Python, or Java.",
        "programming_skills": "Familiarity with microservices architecture and design patterns.",
        "passion": "Enthusiasm for open-source projects."
      },
      "job_description": {
        "philosophy": "Innovate and optimize for better performance.",
        "role_overview": "Join the Kubernetes team to enhance and scale our platform.",
        "impact": "Contribute to the evolution of Kubernetes, impacting millions of users.",
        "mission": "Empowering developers to build scalable applications."
      },
      "responsibilities": [
        "Design and implement new features for Kubernetes.",
        "Collaborate with cross-functional teams to improve product performance.",
        "Mentor junior developers and provide technical guidance.",
        "Contribute to the Kubernetes community through code and documentation."
      ],
      "diversity_statement": "Google is committed to diversity and inclusion in the workplace.",
      "english_proficiency": "English proficiency is required.",
      "note_for_agencies": "Google does not accept unsolicited CVs from agencies."
    },
    {
      "id": "2",
      "title": "Google AI and ML roles",
      "description": "Search some of our newest, priority roles in artificial intelligence and machine learning.",
      "image": "/spot2.jpg",
      "details": "These roles require deep expertise in AI and machine learning, and you will be working on cutting-edge projects...",
      "company": "Google",
      "minimum_qualifications": {
        "degree": "Master's degree or PhD in Computer Science or related field.",
        "experience": [
          "3+ years of experience in AI/ML research or development.",
          "Proficiency in machine learning frameworks such as TensorFlow or PyTorch."
        ]
      },
      "preferred_qualifications": {
        "coding_experience": "Strong programming skills in Python and R.",
        "programming_skills": "Experience with data analysis and visualization tools.",
        "passion": "A passion for solving complex problems with AI."
      },
      "job_description": {
        "philosophy": "Use AI to drive innovation and create value.",
        "role_overview": "Work on groundbreaking AI/ML projects that change the way we interact with technology.",
        "impact": "Shape the future of AI and its applications across various sectors.",
        "mission": "Making AI accessible and useful for everyone."
      },
      "responsibilities": [
        "Develop machine learning models and algorithms.",
        "Analyze large datasets to extract insights.",
        "Collaborate with product teams to integrate AI solutions.",
        "Publish research findings and contribute to open-source projects."
      ],
      "diversity_statement": "Google believes in the power of a diverse workforce.",
      "english_proficiency": "English proficiency is required.",
      "note_for_agencies": "Google does not accept unsolicited CVs from agencies."
    },
    {
      "id": "3",
      "title": "Consumer Hardware",
      "description": "Design and build the systems that are at the heart of the world\"s largest and most powerful computing infrastructure and products.",
      "image": "/spot3.jpg",
      "details": "Join our consumer hardware team to help design cutting-edge products used worldwide...",
      "company": "Google",
      "minimum_qualifications": {
        "degree": "Bachelor's degree in Electrical Engineering or related field.",
        "experience": [
          "4+ years of experience in hardware design and development.",
          "Knowledge of digital and analog circuit design."
        ]
      },
      "preferred_qualifications": {
        "coding_experience": "Experience with embedded systems programming.",
        "programming_skills": "Proficiency in CAD tools and simulation software.",
        "passion": "Desire to innovate and improve hardware products."
      },
      "job_description": {
        "philosophy": "Create devices that enhance people's lives.",
        "role_overview": "Develop consumer hardware that integrates seamlessly with software products.",
        "impact": "Your work will directly influence the usability and functionality of our devices.",
        "mission": "Building products that improve daily life."
      },
      "responsibilities": [
        "Design and prototype new hardware products.",
        "Collaborate with software teams to ensure integration and performance.",
        "Conduct testing and validation of hardware prototypes.",
        "Stay updated with industry trends and technology advancements."
      ],
      "diversity_statement": "Google values diversity in our workforce.",
      "english_proficiency": "English proficiency is required.",
      "note_for_agencies": "Google does not accept unsolicited CVs from agencies."
    },
    {
      "id": "4",
      "title": "Platforms & Ecosystems",
      "description": "Work on our innovative software products that have an impact on people’s lives across the world.",
      "image": "/spot1.jpg",
      "details": "In this role, you will be part of a team that develops platform and ecosystem software to enhance global impact...",
      "company": "Google",
      "minimum_qualifications": {
        "degree": "Bachelor's degree in Computer Science or a related field.",
        "experience": [
          "3+ years of experience in software development.",
          "Experience with cloud platforms and APIs."
        ]
      },
      "preferred_qualifications": {
        "coding_experience": "Experience with Java, Python, or Go.",
        "programming_skills": "Familiarity with microservices and containerization.",
        "passion": "A strong interest in developing scalable software solutions."
      },
      "job_description": {
        "philosophy": "Empower developers with robust tools and frameworks.",
        "role_overview": "Build and maintain software platforms that serve millions.",
        "impact": "Your contributions will enhance the developer experience and user satisfaction.",
        "mission": "Providing platforms that enable innovation and growth."
      },
      "responsibilities": [
        "Develop and maintain platform services and APIs.",
        "Collaborate with product teams to define platform requirements.",
        "Monitor and improve system performance and reliability.",
        "Engage with the developer community to gather feedback and iterate."
      ],
      "diversity_statement": "Google is dedicated to a diverse workforce.",
      "english_proficiency": "English proficiency is required.",
      "note_for_agencies": "Google does not accept unsolicited CVs from agencies."
    }
  ],
"achievements": [
  {
    "id": "1",
    "name": "John Doe",
    "job": "Software Engineer at Google",
    "project": "Developed an AI-based chatbot",
    "testimonial": "GDSC gave me the platform to grow and showcase my skills.",
    "imageUrl": "/Mentor 1.jpeg",
    "date": "2023-08-15",
    "location": "Mountain View, CA",
    "description": "John developed an AI-driven chatbot for customer support, designed to handle thousands of queries per day with over 90% accuracy. The project was part of a larger initiative to streamline user engagement and enhance the user experience on Google platforms.",
    "skills": ["Machine Learning", "NLP", "Python", "TensorFlow"],
    "achievementsDetails": [
      "Improved customer query response time by 40%",
      "Achieved 90% accuracy in understanding and resolving user issues",
      "Presented project at the GDSC annual tech conference"
    ],
    "challenges": [
      "Handling high volumes of data with low latency",
      "Ensuring chatbot responses were contextually accurate and helpful",
      "Integrating the chatbot seamlessly with existing support systems"
    ],
    "lessonsLearned": [
      "The importance of data preprocessing for accurate NLP results",
      "Balancing response time with model complexity",
      "Optimizing performance for real-time applications"
    ],
    "teamSize": 5,
    "duration": "6 months",
    "link": "https://linkedin.com/in/johndoe"
  },
  {
    "id": "2",
    "name": "Jane Smith",
    "job": "Product Manager at Microsoft",
    "project": "Led a successful product launch",
    "testimonial": "I gained hands-on experience and met incredible people.",
    "imageUrl": "/Mentor 2.jpeg",
    "date": "2023-05-10",
    "location": "Seattle, WA",
    "description": "Jane led the product development and launch of a new Microsoft application, focusing on cross-functional collaboration between engineering, marketing, and design teams. Her strategic planning helped secure a 20% market share within the first six months of launch.",
    "skills": ["Product Management", "Team Leadership", "Strategic Planning", "Agile"],
    "achievementsDetails": [
      "Achieved 20% market share in six months",
      "Collaborated with cross-functional teams to meet tight deadlines",
      "Increased user engagement by 30% through user-centered design"
    ],
    "challenges": [
      "Coordinating across multiple departments with differing priorities",
      "Keeping the project on schedule despite unforeseen delays",
      "Balancing feature set with the initial release timeline"
    ],
    "lessonsLearned": [
      "Effective communication is key to cross-functional success",
      "Prioritizing features based on user needs leads to better product reception",
      "Flexibility is essential when dealing with changing project requirements"
    ],
    "teamSize": 10,
    "duration": "9 months",
    "link": "https://linkedin.com/in/janesmith"
  },
  {
    "id": "3",
    "name": "Alex Lee",
    "job": "Data Scientist at Amazon",
    "project": "Created a recommendation engine for e-commerce",
    "testimonial": "Being part of GDSC taught me valuable technical and collaboration skills.",
    "imageUrl": "/Mentor 3.png",
    "date": "2023-09-01",
    "location": "San Francisco, CA",
    "description": "Alex developed a recommendation engine that improved product discovery on Amazon's e-commerce platform. By analyzing customer purchase patterns and preferences, he was able to create personalized product suggestions, boosting sales and customer satisfaction.",
    "skills": ["Data Science", "Python", "Machine Learning", "SQL"],
    "achievementsDetails": [
      "Increased product click-through rate by 25%",
      "Implemented real-time data processing for instant recommendations",
      "Contributed to a 15% increase in sales for recommended products"
    ],
    "challenges": [
      "Handling large volumes of data efficiently",
      "Maintaining recommendation accuracy across diverse user groups",
      "Integrating the engine with existing Amazon systems"
    ],
    "lessonsLearned": [
      "Data cleaning is crucial for accurate recommendations",
      "Real-time processing requires significant optimization",
      "Personalized recommendations improve customer satisfaction"
    ],
    "teamSize": 7,
    "duration": "4 months",
    "link": "https://linkedin.com/in/alexlee"
  },
  {
    "id": "4",
    "name": "Lisa Wong",
    "job": "Frontend Developer at Adobe",
    "project": "Built a responsive UI for a flagship product",
    "testimonial": "GDSC provided me with a platform to learn and connect with amazing tech enthusiasts.",
    "imageUrl": "/Mentor 1.jpeg",
    "date": "2023-07-20",
    "location": "San Jose, CA",
    "description": "Lisa worked on designing and implementing a responsive user interface for Adobe’s flagship product, enhancing usability and aesthetics for millions of users globally. Her work emphasized performance optimization and accessibility, aligning with Adobe's commitment to inclusive design.",
    "skills": ["HTML", "CSS", "JavaScript", "React"],
    "achievementsDetails": [
      "Enhanced page load speed by 35%",
      "Ensured WCAG 2.1 accessibility compliance",
      "Received recognition in Adobe’s annual performance review"
    ],
    "challenges": [
      "Ensuring compatibility across a wide range of devices and screen sizes",
      "Optimizing UI performance without compromising functionality",
      "Meeting accessibility standards"
    ],
    "lessonsLearned": [
      "Accessibility should be a priority from the beginning",
      "Efficient UI design improves both performance and user experience",
      "Cross-device compatibility testing is essential"
    ],
    "teamSize": 4,
    "duration": "3 months",
    "link": "https://linkedin.com/in/lisawong"
  }
],
  "mentors": [
    {
      "id": "1",
      "name": "Mark Johnson",
      "position": "Senior Developer at Meta",
      "bio": "I am excited to mentor students interested in software engineering and AI.",
      "imageUrl": "/Mentor 3.png",
      "linkedinProfile": "https://www.linkedin.com/in/janvi-choudhary/"
    },
    {
      "id": "2",
      "name": "Emily Davis",
      "position": "UX Designer at Spotify",
      "bio": "Happy to guide GDSC members in design thinking and user research.",
      "imageUrl": "/Mentor 1.jpeg",
      "linkedinProfile": "https://www.linkedin.com/feed/"
    },
    {
      "id": "3",
      "name": "Sarah Lee",
      "position": "Data Scientist at Google",
      "bio": "Passionate about helping others understand data analysis and machine learning.",
      "imageUrl": "/Mentor 2.jpeg",
      "linkedinProfile": "https://www.linkedin.com/feed/"
    },
    {
      "id": "4",
      "name": "James Smith",
      "position": "Frontend Engineer at Amazon",
      "bio": "Eager to share my knowledge in React and modern web development practices.",
      "imageUrl": "/Mentor 3.png",
      "linkedinProfile": "https://www.linkedin.com/feed/"
    }
  ],
  "blogs": [
        {
            "id": 1,
            "title": "Understanding Next.js for Modern Web Development",
            "description": "A deep dive into Next.js and how it helps you build scalable, performant websites.",
            "date": "2024-11-06",
            "author": "John Doe",
            "image": "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQMUm-zensaemw84polm_x9DwmIfRr1mDkSkg&s",
            "content": "Next.js, developed by Vercel, has become a go-to framework for developers who want to build scalable and high-performing web applications. With built-in support for server-side rendering (SSR) and static site generation (SSG), Next.js enables faster page loads and better SEO. In this article, we explore the key features that make Next.js unique, including API routes, middleware, and how to optimize data fetching...",
            "tags": ["Next.js", "JavaScript", "Web Development", "Frontend"]
        },
        {
            "id": 2,
            "title": "Introduction to Server-side Rendering in React",
            "description": "Explaining SSR, its importance, and how to implement it in your React apps.",
            "date": "2024-11-05",
            "author": "Jane Smith",
            "image": "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQMUm-zensaemw84polm_x9DwmIfRr1mDkSkg&s",
            "content": "Server-side rendering (SSR) is a technique for improving the loading speed and SEO of your React applications. By rendering the initial HTML on the server, SSR helps deliver faster content to users. This blog discusses how SSR works, the benefits of using it, and practical steps to implement SSR in a React application...",
            "tags": ["SSR", "React", "Web Performance", "JavaScript"]
        },
        {
            "id": 3,
            "title": "Google Material UI in React: A Practical Guide",
            "description": "Learn how to integrate Material UI into your React applications for a modern UI.",
            "date": "2024-11-04",
            "author": "Alice Brown",
            "image": "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQMUm-zensaemw84polm_x9DwmIfRr1mDkSkg&s",
            "content": "Material UI is a popular React UI framework based on Google’s Material Design principles. With Material UI, you can quickly build stylish and responsive applications. In this guide, we cover installation, basic components, themes, and customizations to get you started with Material UI in your React projects...",
            "tags": ["Material UI", "React", "Frontend", "UI Design"]
        },
        {
            "id": 4,
            "title": "React Hooks: The Power of Functional Components",
            "description": "Explore the power of React hooks and why they are important for modern web development.",
            "date": "2024-10-29",
            "author": "Bob Green",
            "image": "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQMUm-zensaemw84polm_x9DwmIfRr1mDkSkg&s",
            "content": "React hooks introduced a new way to handle state and lifecycle events in functional components, revolutionizing the way React developers build components. This article delves into useState, useEffect, and custom hooks, highlighting how these tools simplify state management and create more reusable code...",
            "tags": ["React", "Hooks", "Functional Components", "JavaScript"]
        },
        {
            "id": 5,
            "title": "Visually Appealing UI using Tailwind CSS",
            "description": "Learn how to create beautiful and responsive UIs with Tailwind CSS, a utility-first CSS framework.",
            "date": "2024-09-15",
            "author": "Sally Adams",
            "image": "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQMUm-zensaemw84polm_x9DwmIfRr1mDkSkg&s",
            "content": "Tailwind CSS is a utility-first CSS framework that enables developers to create custom designs without leaving their HTML files. This guide introduces Tailwind’s philosophy, key concepts, and essential classes, providing everything you need to get started with building fast, responsive interfaces...",
            "tags": ["Tailwind CSS", "CSS", "Frontend", "Web Design"]
        },
        {
            "id": 6,
            "title": "JavaScript ES6 Features You Should Know",
            "description": "A look at some of the most useful ES6 features and how they make JavaScript development easier.",
            "date": "2024-07-10",
            "author": "Carlos Mendez",
            "image": "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQMUm-zensaemw84polm_x9DwmIfRr1mDkSkg&s",
            "content": "The ES6 (ECMAScript 2015) release brought significant improvements to JavaScript, making it more developer-friendly and powerful. In this article, we explore some of the must-know features, such as let and const, arrow functions, destructuring, promises, and more, with code examples to illustrate each feature...",
            "tags": ["JavaScript", "ES6", "Programming", "Web Development"]
        },
        {
            "id": 7,
            "title": "Building Scalable APIs with Node.js and Express",
            "description": "A detailed guide on how to create scalable APIs with Node.js and Express.",
            "date": "2024-06-25",
            "author": "Emma White",
            "image": "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQMUm-zensaemw84polm_x9DwmIfRr1mDkSkg&s",
            "content": "Node.js and Express are popular choices for building scalable, server-side applications. This article covers the fundamentals of creating an API, from setting up an Express server to managing routes, middleware, and error handling, with best practices to ensure your API is efficient and maintainable...",
            "tags": ["Node.js", "Express", "API", "Backend"]
        },
        {
            "id": 8,
            "title": "CSS Grid Layout: A Comprehensive Guide",
            "description": "An in-depth guide to CSS Grid and how to use it to create flexible layouts for your websites.",
            "date": "2024-06-01",
            "author": "David Lee",
            "image": "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQMUm-zensaemw84polm_x9DwmIfRr1mDkSkg&s",
            "content": "CSS Grid has revolutionized layout design on the web. With CSS Grid, developers can create complex, responsive grid structures in a more intuitive way than ever before. This guide explains how to get started with CSS Grid, covering key properties, grid lines, and layout techniques...",
            "tags": ["CSS Grid", "CSS", "Frontend", "Web Design"]
        },
        {
            "id": 9,
            "title": "Design Patterns in JavaScript: An Overview",
            "description": "Understand the most common design patterns in JavaScript and how to apply them effectively in your code.",
            "date": "2024-05-20",
            "author": "Fiona Clark",
            "image": "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQMUm-zensaemw84polm_x9DwmIfRr1mDkSkg&s",
            "content": "Design patterns are essential for building scalable and maintainable JavaScript applications. This article covers commonly used patterns such as Singleton, Module, and Observer, providing examples of how to use these patterns in JavaScript projects to write cleaner, more organized code...",
            "tags": ["JavaScript", "Design Patterns", "Programming", "Architecture"]
        },
        {
            "id": 10,
            "title": "The Complete Guide to TypeScript for React",
            "description": "Learn how to use TypeScript in your React applications for better type safety and easier maintenance.",
            "date": "2024-04-10",
            "author": "Grace Johnson",
            "image": "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQMUm-zensaemw84polm_x9DwmIfRr1mDkSkg&s",
            "content": "TypeScript enhances React applications with static typing, making your code safer and easier to maintain. This comprehensive guide covers TypeScript basics, key types, interfaces, and how to apply TypeScript in a React project, with examples and best practices...",
            "tags": ["TypeScript", "React", "JavaScript", "Web Development"]
        }
    ],
    "certifications":[
        {
            "url": "https://developers.google.com/learn/pathways/solution-ai-gemini-101",
            "title": "Getting started with Google AI Studio and the Gemini API using Node.js\n",
            "description": "Learn how to prototype text-based prompts with Google AI Studio and get started writing your first Gemini API Node.js script.\n",
            "playlist": {
                "learningActivities": [
                    {
                        "url": "https://ai.google.dev/gemini-api/docs/ai-studio-quickstart",
                        "title": "Google AI Studio quickstart",
                        "description": "Get started with the Gemini API through this quickstart guide. This documentation highlights the three types of text prompts available via Google AI Studio including freeform, structured and chat prompts.\n",
                        "page": {}
                    },
                    {
                        "url": "https://developers.google.com/codelabs/solutions/ai-gemini-101/codelab-1",
                        "title": "Creating text prompts with Google AI Studio and the Gemini API",
                        "description": "In this codelab, you will write a variety of prompts using Google AI Studio and real-world scenarios with Gemini. You will learn how three different text-based prompts in Google AI Studio work including freeform prompts, structured prompts and chat prompts.\n",
                        "codelab": {}
                    },
                    {
                        "url": "https://developers.google.com/codelabs/solutions/ai-gemini-101/codelab-2",
                        "title": "Writing scripts with the Gemini API",
                        "description": "In this second codelab, we will write a prompt in Google AI Studio with Gemini and migrate it into a stand-alone script we can run in a NodeJS environment. Our script will leverage the Gemini API to access the Gemini model.\n",
                        "codelab": {}
                    },
                    {
                        "url": "https://ai.google.dev/gemini-api/prompts",
                        "title": "Gemini API Prompt Examples",
                        "description": "Explore example prompts for the Gemini API in Google AI Studio. Browse examples for different use cases and learn how to design your own prompts.\n",
                        "page": {}
                    },
                    {
                        "url": "https://developers.google.com/learn/pathways/quizzes/solution-ai-gemini-101",
                        "title": "Quiz",
                        "description": "Test your knowledge and earn your getting started with Gemini API badge.",
                        "quiz": {
                            "badge": {
                                "title": "Getting started with Google AI Studio, Gemini AI and NodeJS.",
                                "description": "Completed the 'Getting started with Google AI Studio, Gemini AI and NodeJS' learning pathway and quiz",
                                "imageUrl": "/static/profile/badges/playlists/solutions/ai-gemini-101/badge.svg",
                                "sharing": {
                                    "title": "Achievement unlocked! I learned about Google AI Studio, Gemini AI and NodeJS. Check it out! #DevBadges",
                                    "description": "Earn this badge when you complete the 'Getting started with Google AI Studio, Gemini AI and NodeJS' learning pathway and quiz.",
                                    "imageUrl": "/static/profile/badges/playlists/solutions/ai-gemini-101/share.png",
                                    "imagePath": "developers.google.com/static/profile/badges/playlists/solutions/ai-gemini-101/share.png"
                                },
                                "url": "https://developers.google.com/profile/badges/playlists/solutions/ai-gemini-101",
                                "imagePath": "developers.google.com/static/profile/badges/playlists/solutions/ai-gemini-101/badge.svg"
                            }
                        }
                    }
                ]
            }
        },
        {
            "url": "https://developers.google.com/learn/pathways/solution-ai-gemini-getting-started-android",
            "title": "Getting started with the Gemini API and Android\n",
            "description": "Learn how to use the Gemini API and the Google AI SDK to prototype generative AI in Android applications.\n",
            "playlist": {
                "learningActivities": [
                    {
                        "url": "https://developers.google.com/learn/pathways/solution-ai-gemini-101",
                        "title": "Introduction to the Gemini API and prompt engineering\n",
                        "description": "<p>\n  Explore Google AI Studio and the capabilities of the Gemini generative AI\n  model. Learn how to design and test the different types of prompts (freeform,\n  structured, and chat) and get an API key for the Gemini API.\n</p> <p>\n  Note that <b>the Google AI client SDK for Android is only for\n  <i>prototyping</i></b> and exploring the Gemini generative AI models.\n  For use cases beyond prototyping (especially production or\n  enterprise-scale apps), use\n  <a\n    href=\"https://firebase.google.com/docs/vertex-ai\"\n    data-label=\"path: https://firebase.google.com/docs/vertex-ai\"\n    data-category=\"devsite-playlist: content link\"\n    class=\"gc-analytics-event\">\n    Vertex AI in Firebase\n  </a>\n  instead.</b> It offers an SDK for Android that has additional security features,\n  support for large media file uploads, and streamlined integrations into the\n  Firebase and Google Cloud ecosystem.\n</p> <p>\n  This pathway can be useful for further experimentation with the Gemini API and\n  lays the groundwork for integrating its features into your application.\n  Optionally, you can also try out the API using a simple NodeJS web\n  application. If you don't already have NodeJS and NPM on your machine, feel\n  free to skip this step and return back to Android in this pathway.\n</p>\n",
                        "playlist": {}
                    },
                    {
                        "url": "https://www.youtube.com/watch?v=L2ORMj0yak8",
                        "title": "Build your own generative AI powered Android app\n",
                        "description": "<p>\n  Watch this talk from Google I/O 2024 to learn how to add generative AI to your\n  Android app using the Gemini API.\n</p> <p>\n  Explore use cases for generative AI in mobile apps and learn how to get\n  started with the Gemini API and the Google AI client SDK on Android.\n</p> <p>\n  <b>The Google AI client SDK for Android is only for <i>prototyping</i>.</b>\n  There are\n    <a\n      href=\"https://ai.google.dev/gemini-api/docs/api-key#security\"\n      data-label=\"path: https://ai.google.dev/gemini-api/docs/api-key#security\"\n      data-category=\"devsite-playlist: content link\"\n      class=\"gc-analytics-event\"\n      >additional security considerations</a\n    >\n  for using the Gemini API key in your mobile client applications since\n  you're risking exposing this API key to malicious actors if it's embedded or\n  retrieved by your client application. So, for use cases beyond prototyping\n  (especially production and enterprise-scale apps),\n  <a\n    href=\"https://firebase.google.com/docs/vertex-ai/migrate-to-vertex-ai?platform=android\"\n    data-label=\"path: https://firebase.google.com/docs/vertex-ai/migrate-to-vertex-ai?platform=android\"\n    data-category=\"devsite-playlist: content link\"\n    class=\"gc-analytics-event\"\n    >migrate to Vertex AI in Firebase</a\n  >\n  to call the Gemini API directly from your client app. Alternatively, you can\n  access the Gemini models server-side through\n  <a\n    href=\"https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/overview\"\n    data-label=\"path: https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/overview\"\n    data-category=\"devsite-playlist: content link\"\n    class=\"gc-analytics-event\"\n    >Vertex AI</a\n  >.\n</p>\n",
                        "page": {}
                    },
                    {
                        "url": "https://ai.google.dev/gemini-api/docs/quickstart",
                        "title": "Introduction to the Google AI client SDK for Android\n",
                        "description": "<p>\n  For mobile apps, you need to consider whether you want to use generative AI\n  with a remote, cloud-based model or a local, on-device model. Take into\n  consideration such factors as network dependency, the size of the model you\n  want to use, cost, and privacy when choosing your approach.\n</p> <p>\n  This solution focuses on using the Google AI client SDK for Android to\n  remotely access the\n  <a\n    href=\"https://ai.google.dev/gemini-api/docs\"\n    data-label=\"path: https://ai.google.dev/gemini-api/docs\"\n    data-category=\"devsite-playlist: content link\"\n    class=\"gc-analytics-event\"\n    >Google AI Gemini API</a\n  >\n  for generative AI. This approach features the following:\n</p> <ul>\n  <li>\n    Is network-dependent and sends data to the cloud for processing access.\n  </li>\n  <li>\n    Provides native Kotlin and Java SDK and does not require working directly\n    with REST APIs or custom server-side integrations.\n  </li>\n\n  <li>\n    Runs on Google's servers, providing access to larger and more performant\n    models without any device or hardware dependencies.\n  </li>\n\n  <li>\n    Easy access to the latest improvements in Google's automatically updated\n    models.\n  </li>\n</ul>\n<p>\n  Getting started with the Google AI client SDK for Android requires setting up\n  a project in Google AI Studio to obtain an API key for the Gemini API. Next,\n  add the required dependencies to your app's build configuration, initialize\n  the model that best fits your use case and submit a prompt to generate output.\n</p> <p>\n  If you want to use the alternative on-device approach, see the next step which\n  covers\n  <a\n    href=\"https://developer.android.com/ai/gemini-nano/\"\n    data-label=\"path: https://developer.android.com/ai/gemini-nano/\"\n    data-category=\"devsite-playlist: content link\"\n    class=\"gc-analytics-event\"\n    >Gemini Nano using the Google AI Edge SDK</a\n  >.\n</p> <p>\n  <b>The Google AI client SDK for Android is only for <i>prototyping</i>.</b>\n  For use cases beyond prototyping (especially production and enterprise-scale apps),\n  <a\n    href=\"https://firebase.google.com/docs/vertex-ai/migrate-to-vertex-ai?platform=android\"\n    data-label=\"path: https://firebase.google.com/docs/vertex-ai/migrate-to-vertex-ai?platform=android\"\n    data-category=\"devsite-playlist: content link\"\n    class=\"gc-analytics-event\"\n    >migrate to Vertex AI in Firebase</a\n  >\n  to call the Gemini API directly from your client app. Alternatively, you can\n  access the Gemini models server-side through\n  <a\n    href=\"https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/overview\"\n    data-label=\"path: https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/overview\"\n    data-category=\"devsite-playlist: content link\"\n    class=\"gc-analytics-event\"\n    >Vertex AI</a\n  >.\n</p> <p>\n  If you use Android Studio, you can quickly get started with the Gemini API\n  template that's described in more detail in a later step.\n</p>\n",
                        "page": {}
                    },
                    {
                        "url": "https://developer.android.com/ai/gemini-nano/experimental",
                        "title": "Access Gemini Nano on-device with the Google AI Edge SDK (experimental)\n",
                        "description": "<p>\n  The alternative approach to using the Google AI client SDK to access the\n  Gemini API is using an on-device AI model such as\n  <a\n    href=\"https://developer.android.com/ai/gemini-nano\"\n    data-label=\"path:https://developer.android.com/ai/gemini-nano\"\n    data-category=\"devsite-playlist: content link\"\n    class=\"gc-analytics-event\"\n    >Gemini Nano powered by Android AICore through the Google AI Edge SDK for\n    Android</a\n  >.\n</p> <p>\n  Instead of calling a remote service that provides access to a generative AI\n  model, the prompts are processed by a model that is stored on the device\n  itself. This option removes the dependency on network access and completes all\n  processing on-device. Consider this approach for potential cost-savings,\n  offline access, smaller and narrower tasks, as well as local processing of\n  sensitive data for your app.\n</p> <p>\n  Gemini Nano is available for experimental access using the Google AI Edge\n  SDK. Get started experimenting with Gemini Nano in your own app and\n  <a\n    href=\"https://developer.android.com/ai/gemini-nano/experimental\"\n    data-label=\"path: https://developer.android.com/ai/gemini-nano/experimental\"\n    data-category=\"devsite-playlist: content link\"\n    class=\"gc-analytics-event\"\n    >follow the guide to begin experimenting with on-device AI capabilities to enhance your\n    app</a\n  >.\n</p>\n",
                        "page": {}
                    },
                    {
                        "url": "https://developer.android.com/studio/projects/templates",
                        "title": "Build with the Google AI client SDK in Android Studio\n",
                        "description": "<p>\n  Android Studio includes a new project template for the Gemini API that helps\n  you explore and prototype generative AI in Android apps with the Google AI\n  client SDK.\n</p> <p>\n  Follow the steps in the template to set up an API key (if you don't already\n  have one). Then, configure the application and make your first API call. The\n  template automatically sets up an Android app that connects to the Gemini API\n  and summarizes text.\n</p> <p>\n  Note that there are\n  <a\n    href=\"https://ai.google.dev/gemini-api/docs/api-key#security\"\n    data-label=\"path: https://ai.google.dev/gemini-api/docs/api-key#security\"\n    data-category=\"devsite-playlist: content link\"\n    class=\"gc-analytics-event\"\n    >additional security considerations</a\n  >\n  for using API keys directly in mobile client applications. The final step in\n  this solution shows how to prepare your Android app for use cases beyond prototyping\n  (most importantly, production) by\n  <a\n    href=\"https://firebase.google.com/docs/vertex-ai/migrate-to-vertex-ai?platform=android\"\n    data-label=\"path: https://firebase.google.com/docs/vertex-ai/migrate-to-vertex-ai?platform=android\"\n    data-category=\"devsite-playlist: content link\"\n    class=\"gc-analytics-event\"\n    >migrating to Vertex AI in Firebase</a\n  >\n  to access the Gemini API.\n</p>\n",
                        "page": {}
                    },
                    {
                        "url": "https://github.com/google/generative-ai-android/tree/main/generativeai-android-sample",
                        "title": "Explore the Android sample apps in Kotlin\n",
                        "description": "<p>\n  Explore the generative AI sample app for the Google AI client SDK for Android.\n</p> <p>\n  This example app demonstrates three key use cases: generating text, photo\n  reasoning (using multimodal inputs), and multi-turn conversations (chat). It\n  also shows how to use\n  <a\n    href=\"https://ai.google.dev/api/generate-content#text_gen_text_only_prompt_streaming-KOTLIN\"\n    data-label=\"path: https://ai.google.dev/api/generate-content#text_gen_text_only_prompt_streaming-KOTLIN\"\n    data-category=\"devsite-playlist: content link\"\n    class=\"gc-analytics-event\"\n    >content streaming</a\n  >\n  to improve response time by displaying partial results.\n</p> <p>\n  Follow the steps in the <code translate=\"no\" dir=\"ltr\">README</code> to get started, which includes\n  configuring your Gemini API key.\n</p>\n",
                        "page": {}
                    },
                    {
                        "url": "https://ai.google.dev/gemini-api/docs/file-prompting-strategies",
                        "title": "Multimodal prompting using the Google AI SDK\n",
                        "description": "<p>\n  Multimodal prompts combine different types of media together, such as text,\n  images, and audio. For example, you could create prompts that identify objects\n  in an image, extract text from a photo, or reference a picture.\n</p> <p>\n  To get started, read this guide about file prompting strategies and multimodal\n  concepts, which includes best practices for designing multimodal prompts.\n</p> <p>\n  Next, explore the multimodal capabilities of the Gemini models in\n  <a\n    href=\"https://aistudio.google.com/\"\n    data-label=\"path: https://aistudio.google.com/\"\n    data-category=\"devsite-playlist: content link\"\n    class=\"gc-analytics-event external\"\n    >Google AI Studio</a\n  >\n  by uploading or selecting a file as part of your prompt.\n</p> <p>\n  <a\n    href=\"https://ai.google.dev/api/generate-content#text_gen_multimodal_one_image_prompt-KOTLIN\"\n    data-label=\"path: https://ai.google.dev/api/generate-content#text_gen_multimodal_one_image_prompt-KOTLIN\"\n    data-category=\"devsite-playlist: content link\"\n    class=\"gc-analytics-event\"\n    >Learn how to use multimodal inputs</a\n  >\n  using the Google AI client SDK for Android, find\n  <a\n    href=\"https://ai.google.dev/gemini-api/docs/vision#prompting-images\"\n    data-label=\"path: https://ai.google.dev/gemini-api/docs/vision#prompting-images\"\n    data-category=\"devsite-playlist: content link\"\n    class=\"gc-analytics-event\"\n    >image requirements for prompts</a\n  >, and explore the\n  <a\n    href=\"https://github.com/google/generative-ai-android/tree/main/generativeai-android-sample#features\"\n    data-label=\"path: https://github.com/google/generative-ai-android/tree/main/generativeai-android-sample#features\"\n    data-category=\"devsite-playlist: content link\"\n    class=\"gc-analytics-event external\"\n    >multimodal photo reasoning demo in the sample app</a\n  >.\n</p>\n<p>\n  For further reading, see the solution\n  <a\n    href=\"https://developers.google.com/learn/pathways/solution-ai-gemini-images\"\n    data-label=\"path: https://developers.google.com/learn/pathways/solution-ai-gemini-images\"\n    data-category=\"devsite-playlist: content link\"\n    class=\"gc-analytics-event\"\n    >Leveraging the Gemini Pro Vision model for image understanding, multimodal\n    prompts and accessibility</a\n  >.\n</p>\n",
                        "page": {}
                    },
                    {
                        "url": "https://firebase.google.com/docs/vertex-ai/migrate-to-vertex-ai",
                        "title": "Prepare for production by migrating to Vertex AI in Firebase\n",
                        "description": "<p>\n  <i>Using the Google AI client SDK for Android to call the Gemini API directly\n  from a mobile client is only for prototyping and experimentation.</i>\n  When you start to seriously develop your app beyong prototyping (especially as\n  you prepare for production), transition to use Vertex AI in Firebase and its\n  SDK for Android.\n</p> <p>\n  <b>For calling the Gemini API directly from your Android app, we strongly\n  recommend using the Vertex AI in Firebase client SDK for Android.</b>\n  This SDK offers enhanced security features for mobile apps, including\n  Firebase App Check to help protect your app from unauthorized client access.\n  When you use this SDK, you can include large media files in your requests by\n  using Cloud Storage for Firebase.\n  Vertex AI in Firebase also integrates with other products in Google's Firebase\n  developer platform (like Cloud Firestore and Firebase Remote Config), while also\n  giving you streamlined access to the tools, workflows, and scale offered through\n  Google Cloud.\n  <a\n    href=\"https://cloud.google.com/vertex-ai/generative-ai/docs/migrate/migrate-google-ai#google-ai\"\n    data-label=\"path: https://cloud.google.com/vertex-ai/generative-ai/docs/migrate/migrate-google-ai\"\n    data-category=\"devsite-playlist: content link\"\n    class=\"gc-analytics-event\"\n    >Among other differences</a\n  >\n  , Vertex AI also supports increased request quotas and enterprise features.\n</p> <p>\n  Follow this guide to migrate to the Vertex AI in Firebase client SDK by\n  updating your package dependencies, imports, and changing how the AI model is\n  initialized.\n</p>\n",
                        "page": {}
                    },
                    {
                        "url": "https://developers.google.com/learn/pathways/quizzes/solution-ai-gemini-getting-started-android",
                        "title": "Quiz",
                        "description": "Test your knowledge and earn your 'Getting started with the Gemini API and Android' badge.",
                        "quiz": {
                            "badge": {
                                "title": "Getting started with the Gemini API and Android",
                                "description": "Completed the 'Getting started with the Gemini API and Android' learning pathway and quiz\n",
                                "imageUrl": "/static/profile/badges/playlists/solutions/ai-gemini-getting-started-android/badge.svg",
                                "sharing": {
                                    "title": "Achievement unlocked! I learned about getting started with the Gemini API and Android. Check it out! #DevBadges",
                                    "description": "Earn this badge when you complete the 'Getting started with the Gemini API and Android' learning pathway and quiz.",
                                    "imageUrl": "/static/profile/badges/playlists/solutions/ai-gemini-getting-started-android/share.png",
                                    "imagePath": "developers.google.com/static/profile/badges/playlists/solutions/ai-gemini-getting-started-android/share.png"
                                },
                                "url": "https://developers.google.com/profile/badges/playlists/solutions/ai-gemini-getting-started-android",
                                "imagePath": "developers.google.com/static/profile/badges/playlists/solutions/ai-gemini-getting-started-android/badge.svg"
                            }
                        }
                    }
                ]
            }
        },
        {
            "url": "https://developers.google.com/learn/pathways/solution-ai-gemini-getting-started-dart-flutter",
            "title": "Getting started with the Gemini API and Dart and Flutter\n",
            "description": "Learn how to use the Gemini API and the Google AI Dart SDK to prototype generative AI in Dart and Flutter applications.\n",
            "playlist": {
                "learningActivities": [
                    {
                        "url": "https://developers.google.com/learn/pathways/solution-ai-gemini-101",
                        "title": "Introduction to the Gemini API and prompt engineering\n",
                        "description": "<p>\n  Explore Google AI Studio and the capabilities of the Gemini generative AI\n  model. Learn how to design and test the different types of prompts (freeform,\n  structured, and chat) and get an API key for the Gemini API.\n</p> <p>\n  This pathway can be useful for further experimentation with the Gemini API and\n  lays the groundwork for integrating its features into your application.\n  Optionally, you can also try out the API using a simple NodeJS web\n  application. If you don't already have NodeJS and NPM on your machine, feel\n  free to skip this step and return back to Dart and Flutter in this pathway.\n</p> <p>\n  Note that <b>calling the Gemini API directly from your mobile or web app using\n  the Google AI Dart SDK is only for <i>prototyping</i></b> and exploring the\n  Gemini generative AI models. For use cases beyond prototyping\n  (especially production or enterprise-scale apps), use\n  <a\n    href=\"https://firebase.google.com/docs/vertex-ai\"\n    data-label=\"path: https://firebase.google.com/docs/vertex-ai\"\n    data-category=\"devsite-playlist: content link\"\n    class=\"gc-analytics-event\">\n    Vertex AI in Firebase\n  </a>\n  instead.</b> It offers an SDK for Flutter that has additional security features,\n  support for large media file uploads, and streamlined integrations into the\n  Firebase and Google Cloud ecosystem. Alternatively, you can use the\n  Google AI Dart SDK to access the Gemini models server-side.\n</p>\n",
                        "playlist": {}
                    },
                    {
                        "url": "https://dartpad.dev/?sample=google-ai-sdk",
                        "title": "Run the Google AI SDK sample on DartPad\n",
                        "description": "<p>Try out a Flutter demo of the Google AI Dart SDK on DartPad.</p> <p>\n  This interactive demo shows how to build a chat app in Flutter that uses the\n  multi-turn conversations functionality from the SDK. Learn how to implement\n  the user interface and manage the state of the conversation.\n</p> <p>Enter your Gemini API key when prompted to get started.</p>\n",
                        "page": {}
                    },
                    {
                        "url": "https://www.youtube.com/watch?v=B1RKFL6ASts",
                        "title": "Gemini API and Flutter: Practical, AI-Driven apps with Google AI tools\n",
                        "description": "<p>\n  Watch this talk from Google I/O 2024 to get an overview about generative AI,\n  Google AI Studio, and prompt design.\n</p> <p>\n  Follow along to integrate the Google AI Dart SDK into a Flutter application and\n  build a recipe application that uses the Gemini 1.5 Pro model with multimodal\n  prompts.\n</p>\n",
                        "page": {}
                    },
                    {
                        "url": "https://ai.google.dev/gemini-api/docs/quickstart",
                        "title": "Introduction to the Google AI Dart SDK\n",
                        "description": "<p>\n  The\n  <a\n    href=\"https://github.com/google/generative-ai-dart\"\n    data-label=\"path: https://github.com/google/generative-ai-dart\"\n    data-category=\"devsite-playlist: content link\"\n    class=\"gc-analytics-event external\"\n    >Google AI Dart SDK</a\n  >\n  is a Dart-first, cross-platform SDK for building your generative AI\n  integration with the\n  <a\n    href=\"https://ai.google.dev/gemini-api/docs\"\n    data-label=\"path: https://ai.google.dev/gemini-api/docs\"\n    data-category=\"devsite-playlist: content link\"\n    class=\"gc-analytics-event\"\n    >Google AI Gemini API</a\n  >. This SDK also supports Flutter on all platforms.\n</p> <p>\n  <b>When calling the Gemini API directly from your mobile or web app, the\n  Google AI Dart SDK is only for <i>prototyping</i>.</b>\n  There are\n    <a\n      href=\"https://ai.google.dev/gemini-api/docs/api-key#security\"\n      data-label=\"path: https://ai.google.dev/gemini-api/docs/api-key#security\"\n      data-category=\"devsite-playlist: content link\"\n      class=\"gc-analytics-event\"\n      >additional security considerations</a\n    >\n  for using the Gemini API key in your web and mobile client applications since\n  you're risking exposing this API key to malicious actors if it's embedded or\n  retrieved by your client application. So, for use cases beyond prototyping\n  (especially production and enterprise-scale apps),\n    <a\n      href=\"https://firebase.google.com/docs/vertex-ai/migrate-to-vertex-ai?platform=flutter\"\n      data-label=\"path: https://firebase.google.com/docs/vertex-ai/migrate-to-vertex-ai?platform=flutter\"\n      data-category=\"devsite-playlist: content link\"\n      class=\"gc-analytics-event\"\n      >migrate to Vertex AI in Firebase</a\n    >\n  to call the Gemini API directly from your client app. Alternatively, you can access the\n  Gemini models server-side using either the Google AI Dart SDK or through\n    <a\n      href=\"https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/overview\"\n      data-label=\"path: https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/overview\"\n      data-category=\"devsite-playlist: content link\"\n      class=\"gc-analytics-event\"\n      >Vertex AI</a\n    >.\n</p> <p>\n  To get started with the Google AI Dart SDK, set up a project in Google AI Studio,\n  which includes obtaining an API key for the Gemini API. Next, add the\n  required dependencies to your app's <code translate=\"no\" dir=\"ltr\">pubspec.yaml</code>\n  (<code translate=\"no\" dir=\"ltr\">google_generative_ai</code>). Then, you can initialize the library with\n  your API key and make your first API call.\n</p> <p>\n  You can also\n  <a\n    href=\"https://www.youtube.com/shorts/1AuzJEiHjO4\"\n    data-label=\"path: https://www.youtube.com/shorts/1AuzJEiHjO4\"\n    data-category=\"devsite-playlist: content link\"\n    class=\"gc-analytics-event external\"\n    >check out this YouTube Short</a\n  >\n  for a quick overview over the Google AI Dart SDK and how to get started.\n</p>\n",
                        "page": {}
                    },
                    {
                        "url": "https://github.com/google/generative-ai-dart/tree/main?tab=readme-ov-file#dart-samples",
                        "title": "Explore the Dart SDK and Flutter sample apps\n",
                        "description": "<p>\n  Explore the generative AI example apps for the Google AI Dart SDK for Flutter\n  and Dart.\n</p> <p>\n  The\n  <a\n    href=\"https://github.com/google/generative-ai-dart/tree/main/samples/dart\"\n    data-label=\"path: https://github.com/google/generative-ai-dart/tree/main/samples/dart\"\n    data-category=\"devsite-playlist: content link\"\n    class=\"gc-analytics-event external\"\n    >Dart code samples</a\n  >\n  demonstrate three key use cases:\n  <a\n    href=\"https://github.com/google/generative-ai-dart/blob/main/samples/dart/bin/simple_text.dart\"\n    data-label=\"path: https://github.com/google/generative-ai-dart/blob/main/samples/dart/bin/simple_text.dart\"\n    data-category=\"devsite-playlist: content link\"\n    class=\"gc-analytics-event\"\n    >generating text</a\n  >,\n  <a\n    href=\"https://github.com/google/generative-ai-dart/blob/main/samples/dart/bin/simple_text_and_image.dart\"\n    data-label=\"path: https://github.com/google/generative-ai-dart/blob/main/samples/dart/bin/simple_text_and_image.dart\"\n    data-category=\"devsite-playlist: content link\"\n    class=\"gc-analytics-event external\"\n    >photo reasoning (using multimodal inputs)</a\n  >, and\n  <a\n    href=\"https://github.com/google/generative-ai-dart/blob/main/samples/dart/bin/simple_chat.dart\"\n    data-label=\"path: https://github.com/google/generative-ai-dart/blob/main/samples/dart/bin/simple_chat.dart\"\n    data-category=\"devsite-playlist: content link\"\n    class=\"gc-analytics-event external\"\n    >multi-turn conversations (chat)</a\n  >. It also shows advanced topics, such as how to use\n  <a\n    href=\"https://github.com/google/generative-ai-dart/blob/main/samples/dart/bin/advanced_text.dart\"\n    data-label=\"path: https://github.com/google/generative-ai-dart/blob/main/samples/dart/bin/advanced_text.dart\"\n    data-category=\"devsite-playlist: content link\"\n    class=\"gc-analytics-event external\"\n    >content streaming</a\n  >\n  to improve response time by displaying partial results.\n</p> <p>\n  The\n  <a\n    href=\"https://github.com/google/generative-ai-dart/tree/main/samples/flutter_app\"\n    data-label=\"path: https://github.com/google/generative-ai-dart/tree/main/samples/flutter_app\"\n    data-category=\"devsite-playlist: content link\"\n    class=\"gc-analytics-event external\"\n    >Flutter sample app</a\n  >\n  demonstrates how to implement multi-turn conversations (chat) and photo\n  reasoning (using multimodal inputs) in a multi-platform application.\n</p> <p>\n  Follow the steps in the <code translate=\"no\" dir=\"ltr\">README</code> for each sample to get started,\n  which includes configuring your Gemini API key and providing it as an\n  environment variable.\n</p>\n",
                        "page": {}
                    },
                    {
                        "url": "https://ai.google.dev/gemini-api/docs/file-prompting-strategies",
                        "title": "Multimodal prompting using the Google AI Dart SDK\n",
                        "description": "<p>\n  Multimodal prompts combine different types of media together, such as text,\n  images, and audio. For example, you could create prompts that identify objects\n  in an image, extract text from a photo, or reference a picture.\n</p> <p>\n  To get started, read this guide about file prompting strategies and multimodal\n  concepts, which includes best practices for designing multimodal prompts.\n</p> <p>\n  Next, explore the multimodal capabilities of the Gemini models in\n  <a\n    href=\"https://aistudio.google.com/\"\n    data-label=\"path: https://aistudio.google.com/\"\n    data-category=\"devsite-playlist: content link\"\n    class=\"gc-analytics-event external\"\n    >Google AI Studio</a\n  >\n  by uploading or selecting a file as part of your prompt.\n</p> <p>\n  <a\n    href=\"https://ai.google.dev/api/generate-content#text_gen_multimodal_one_image_prompt-DART\"\n    data-label=\"path: https://ai.google.dev/api/generate-content#text_gen_multimodal_one_image_prompt-DART\"\n    data-category=\"devsite-playlist: content link\"\n    class=\"gc-analytics-event\"\n    >Learn how to use multimodal inputs</a\n  >\n  using the Google AI Dart SDK, find\n  <a\n    href=\"https://ai.google.dev/gemini-api/docs/vision#prompting-images\"\n    data-label=\"path: https://ai.google.dev/gemini-api/docs/vision#prompting-images\"\n    data-category=\"devsite-playlist: content link\"\n    class=\"gc-analytics-event\"\n    >image requirements for prompts</a\n  >, and explore the\n  <a\n    href=\"https://github.com/google/generative-ai-dart/tree/main/samples/flutter_app\"\n    data-label=\"path: https://github.com/google/generative-ai-dart/tree/main/samples/flutter_app\"\n    data-category=\"devsite-playlist: content link\"\n    class=\"gc-analytics-event external\"\n    >multimodal image chat demo in the Flutter sample app</a\n  >\n  or in the\n  <a\n    href=\"https://github.com/google/generative-ai-dart/blob/main/samples/dart/bin/simple_text_and_image.dart\"\n    data-label=\"path: https://github.com/google/generative-ai-dart/blob/main/samples/dart/bin/simple_text_and_image.dart\"\n    data-category=\"devsite-playlist: content link\"\n    class=\"gc-analytics-event external\"\n    >Dart sample scripts</a\n  >.\n</p> <p>\n  For further reading, see the solution\n  <a\n    href=\"https://developers.google.com/learn/pathways/solution-ai-gemini-images\"\n    data-label=\"path: https://developers.google.com/learn/pathways/solution-ai-gemini-images\"\n    data-category=\"devsite-playlist: content link\"\n    class=\"gc-analytics-event\"\n    >Leveraging the Gemini Pro Vision model for image understanding, multimodal\n    prompts and accessibility</a\n  >.\n</p>\n",
                        "page": {}
                    },
                    {
                        "url": "https://firebase.google.com/docs/vertex-ai/migrate-to-vertex-ai",
                        "title": "Prepare for production by migrating to Vertex AI in Firebase\n",
                        "description": "<p>\n  <i>Using the Google AI Dart SDK to call the Gemini API directly\n  from a web or mobile client is only for prototyping and experimentation.</i>\n  When you start to seriously develop your app beyong prototyping (especially as\n  you prepare for production), transition to use Vertex AI in Firebase and its\n  SDK for Flutter.\n</p> <p>\n  <b>For calling the Gemini API directly from your web or mobile app, we strongly\n  recommend using the Vertex AI in Firebase client SDK for Flutter.</b>\n  This SDK offers enhanced security features for web and mobile apps, including\n  Firebase App Check to help protect your app from unauthorized client access.\n  When you use this SDK, you can include large media files in your requests by\n  using Cloud Storage for Firebase.\n  Vertex AI in Firebase also integrates with other products in Google's Firebase\n  developer platform (like Cloud Firestore and Firebase Remote Config), while also\n  giving you streamlined access to the tools, workflows, and scale offered through\n  Google Cloud.\n  <a\n    href=\"https://cloud.google.com/vertex-ai/generative-ai/docs/migrate/migrate-google-ai#google-ai\"\n    data-label=\"path: https://cloud.google.com/vertex-ai/generative-ai/docs/migrate/migrate-google-ai\"\n    data-category=\"devsite-playlist: content link\"\n    class=\"gc-analytics-event\"\n    >Among other differences</a\n  >\n  , Vertex AI also supports increased request quotas and enterprise features.\n</p> <p>\n  Follow this guide to migrate to the Vertex AI in Firebase client SDK by\n  updating your package dependencies, imports, and changing how the AI model is\n  initialized.\n</p>\n",
                        "page": {}
                    },
                    {
                        "url": "https://developers.google.com/learn/pathways/quizzes/solution-ai-gemini-getting-started-dart-flutter",
                        "title": "Quiz",
                        "description": "Test your knowledge and earn your 'Getting started with the Gemini API and Dart and Flutter' badge.",
                        "quiz": {
                            "badge": {
                                "title": "Getting started with the Gemini API and Dart and Flutter",
                                "description": "Completed the 'Getting started with the Gemini API and Dart and Flutter' learning pathway and quiz\n",
                                "imageUrl": "/static/profile/badges/playlists/solutions/ai-gemini-getting-started-dart-flutter/badge.svg",
                                "sharing": {
                                    "title": "Achievement unlocked! I learned about getting started with the Gemini API and Dart and Flutter. Check it out! #DevBadges",
                                    "description": "Earn this badge when you complete the 'Getting started with the Gemini API and Dart and Flutter' learning pathway and quiz.",
                                    "imageUrl": "/static/profile/badges/playlists/solutions/ai-gemini-getting-started-dart-flutter/share.png",
                                    "imagePath": "developers.google.com/static/profile/badges/playlists/solutions/ai-gemini-getting-started-dart-flutter/share.png"
                                },
                                "url": "https://developers.google.com/profile/badges/playlists/solutions/ai-gemini-getting-started-dart-flutter",
                                "imagePath": "developers.google.com/static/profile/badges/playlists/solutions/ai-gemini-getting-started-dart-flutter/badge.svg"
                            }
                        }
                    }
                ]
            }
        },
        {
            "url": "https://developers.google.com/learn/pathways/solution-ai-gemini-getting-started-swift",
            "title": "Getting started with the Gemini API and Swift\n",
            "description": "Learn how to use the Gemini API and the Google AI Swift SDK to prototype generative AI with Swift. Use the Google AI Swift SDK to make your first generative AI call using the Gemini API in your application. Explore a sample application and learn how to make multimodal prompts (that combine image and text).\n",
            "playlist": {
                "learningActivities": [
                    {
                        "url": "https://developers.google.com/learn/pathways/solution-ai-gemini-101",
                        "title": "Introduction to the Gemini API and prompt engineering\n",
                        "description": "<p>\n  Explore Google AI Studio and the capabilities of the Gemini generative AI\n  model. Learn how to design and test the different types of prompts (freeform,\n  structured, and chat) and get an API key for the Gemini API.\n</p> <p>\n  Note that <b>the Google AI Swift SDK is only for <i>prototyping</i></b> and\n  exploring the Gemini generative AI models. For use cases beyond prototyping\n  (especially production or enterprise-scale apps), use\n  <a\n    href=\"https://firebase.google.com/docs/vertex-ai\"\n    data-label=\"path: https://firebase.google.com/docs/vertex-ai\"\n    data-category=\"devsite-playlist: content link\"\n    class=\"gc-analytics-event\">\n    Vertex AI in Firebase\n  </a>\n  instead.</b> It offers an SDK for Swift that has additional security features,\n  support for large media file uploads, and streamlined integrations into the\n  Firebase and Google Cloud ecosystem.\n</p> <p>\n  This pathway can be useful for further experimentation with the Gemini API and\n  lays the groundwork for integrating its features into your application.\n  Optionally, you can also try out the Gemini API using a simple NodeJS web\n  application. If you don't already have NodeJS and NPM on your machine, feel\n  free to skip this step and return back to Swift in this pathway.\n</p>\n",
                        "playlist": {}
                    },
                    {
                        "url": "https://ai.google.dev/gemini-api/docs/quickstart",
                        "title": "Introduction to the Google AI Swift SDK\n",
                        "description": "<p>\n  The\n  <a\n    href=\"https://github.com/google/generative-ai-swift\"\n    data-label=\"path: https://github.com/google/generative-ai-swift\"\n    data-category=\"devsite-playlist: content link\"\n    class=\"gc-analytics-event external\">\n    Google AI Swift SDK\n  </a>\n  is a Swift-first, cross-platform SDK that gives you access to the\n  <a\n    href=\"https://ai.google.dev/gemini-api/docs\"\n    data-label=\"path: https://ai.google.dev/gemini-api/docs\"\n    data-category=\"devsite-playlist: content link\"\n    class=\"gc-analytics-event external\">\n    Google AI Gemini API</a\n  >\n  for prototyping your generative AI integration. This SDK supports Swift on\n  most platforms.\n</p> <p>\n  To get started with the Google AI Swift SDK, set up a project in Google AI\n  Studio, which includes obtaining an API key for the Gemini API. Next, add the\n  <code translate=\"no\" dir=\"ltr\">GoogleGenerativeAI</code>\n  package to your app's project configuration. Then, you can initialize the\n  generative model and make your first API call.\n</p> <p>\n  <b>The Google AI Swift SDK is only for <i>prototyping</i>.</b>\n  There are\n    <a\n      href=\"https://ai.google.dev/gemini-api/docs/api-key#security\"\n      data-label=\"path: https://ai.google.dev/gemini-api/docs/api-key#security\"\n      data-category=\"devsite-playlist: content link\"\n      class=\"gc-analytics-event\"\n      >additional security considerations</a\n    >\n  for using the Gemini API key in your mobile client applications since\n  you're risking exposing this API key to malicious actors if it's embedded or\n  retrieved by your client application. So, for use cases beyond prototyping\n  (especially production and enterprise-scale apps),\n    <a\n      href=\"https://firebase.google.com/docs/vertex-ai/migrate-to-vertex-ai?platform=ios\"\n      data-label=\"path: https://firebase.google.com/docs/vertex-ai/migrate-to-vertex-ai?platform=ios\"\n      data-category=\"devsite-playlist: content link\"\n      class=\"gc-analytics-event\"\n      >migrate to Vertex AI in Firebase</a\n    >\n  to call the Gemini API directly from your client app. Alternatively, you can\n  access the Gemini models server-side through\n    <a\n      href=\"https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/overview\"\n      data-label=\"path: https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/overview\"\n      data-category=\"devsite-playlist: content link\"\n      class=\"gc-analytics-event\"\n      >Vertex AI</a\n    >.\n</p>\n",
                        "page": {}
                    },
                    {
                        "url": "https://github.com/google/generative-ai-swift?tab=readme-ov-file#try-out-the-sample-swift-app",
                        "title": "Explore the Swift SDK and sample apps\n",
                        "description": "<p>\n  Explore more advanced use cases for the Google AI Swift SDK with code samples\n  and demo apps on GitHub.\n</p> <p>\n  The\n  <a\n    href=\"https://github.com/google/generative-ai-swift/tree/main/Examples/GenerativeAISample\"\n    data-category=\"devsite-playlist: content link\"\n    data-label=\"path: https://github.com/google/generative-ai-swift/tree/main/Examples/GenerativeAISample\"\n    class=\"gc-analytics-event external\">\n    Swift code samples\n  </a>\n  demonstrate three key use cases:\n  <a\n    href=\"https://github.com/google/generative-ai-swift/blob/main/Examples/GenerativeAISample/GenerativeAITextSample/ViewModels/SummarizeViewModel.swift\"\n    data-label=\"path: https://github.com/google/generative-ai-swift/blob/main/Examples/GenerativeAISample/GenerativeAITextSample/ViewModels/SummarizeViewModel.swift\"\n    data-category=\"devsite-playlist: content link\"\n    class=\"gc-analytics-event external\">\n    generating text\n  </a>\n  ,\n  <a\n    href=\"https://github.com/google/generative-ai-swift/blob/main/Examples/GenerativeAISample/GenerativeAIMultimodalSample/ViewModels/PhotoReasoningViewModel.swift\"\n    data-label=\"path: https://github.com/google/generative-ai-swift/blob/main/Examples/GenerativeAISample/GenerativeAIMultimodalSample/ViewModels/PhotoReasoningViewModel.swift\"\n    data-category=\"devsite-playlist: content link\"\n    class=\"gc-analytics-event external\">\n    photo reasoning (using multimodal inputs)\n  </a>\n  , and\n  <a\n    href=\"https://github.com/google/generative-ai-swift/blob/main/Examples/GenerativeAISample/ChatSample/ViewModels/ConversationViewModel.swift\"\n    data-label=\"path: https://github.com/google/generative-ai-swift/blob/main/Examples/GenerativeAISample/ChatSample/ViewModels/ConversationViewModel.swift\"\n    data-category=\"devsite-playlist: content link\"\n    class=\"gc-analytics-event external\">\n    multi-turn conversations (chat)\n  </a>\n  . They also show how to use content streaming to improve response time by\n  displaying partial results.\n</p> <p>\n  Follow the steps in the <code translate=\"no\" dir=\"ltr\">README</code> to get started, which includes\n  setting up your Gemini API Key and providing it in a <code translate=\"no\" dir=\"ltr\">.plist</code> file.\n</p>\n",
                        "page": {}
                    },
                    {
                        "url": "https://ai.google.dev/gemini-api/docs/file-prompting-strategies",
                        "title": "Multimodal prompting using the Google AI Swift SDK\n",
                        "description": "<p>\n  Multimodal prompts combine different types of media together, such as text,\n  images, and audio. For example, you could create prompts that identify objects\n  in an image, extract text from a photo, or reference a picture.\n</p> <p>\n  To get started, read this guide about file prompting strategies and multimodal\n  concepts, which includes best practices for designing multimodal prompts.\n</p> <p>\n  Next, explore the multimodal capabilities of the Gemini models in\n  <a\n    href=\"https://aistudio.google.com/\"\n    data-label=\"path: https://aistudio.google.com/\"\n    data-category=\"devsite-playlist: content link\"\n    class=\"gc-analytics-event external\">\n      Google AI Studio\n  </a>\n  by uploading or selecting a file as part of your prompt.\n</p> <p>\n  <a\n    href=\"https://ai.google.dev/api/generate-content#text_gen_multimodal_one_image_prompt-SWIFT\"\n    data-label=\"path: https://ai.google.dev/api/generate-content#text_gen_multimodal_one_image_prompt-SWIFT\"\n    data-category=\"devsite-playlist: content link\"\n    class=\"gc-analytics-event\">\n      Learn how to use multimodal inputs\n  </a>\n  using the Google AI Swift SDK, find\n  <a\n    href=\"https://ai.google.dev/gemini-api/docs/vision#prompting-images\"\n    data-label=\"path: https://ai.google.dev/gemini-api/docs/vision#prompting-images\"\n    data-category=\"devsite-playlist: content link\"\n    class=\"gc-analytics-event\"\n    >\n    image requirements for prompts\n  </a>\n  , and explore the\n  <a\n    href=\"https://github.com/google/generative-ai-swift/blob/main/Examples/GenerativeAISample/GenerativeAIMultimodalSample/ViewModels/PhotoReasoningViewModel.swift\"\n    data-label=\"path: https://github.com/google/generative-ai-swift/blob/main/Examples/GenerativeAISample/GenerativeAIMultimodalSample/ViewModels/PhotoReasoningViewModel.swift\"\n    data-category=\"devsite-playlist: content link\"\n    class=\"gc-analytics-event external\">\n      multimodal image demo in the Swift sample app\n  </a>\n  .\n</p> <p>\n  For further reading, see the solution\n  <a\n    href=\"https://developers.google.com/learn/pathways/solution-ai-gemini-images\"\n    data-label=\"path: https://developers.google.com/learn/pathways/solution-ai-gemini-images\"\n    data-category=\"devsite-playlist: content link\"\n    class=\"gc-analytics-event\">\n    Leveraging the Gemini Pro Vision model for image understanding, multimodal\n    prompts and accessibility\n    </a>\n    .\n</p>\n",
                        "page": {}
                    },
                    {
                        "url": "https://firebase.google.com/docs/vertex-ai/migrate-to-vertex-ai",
                        "title": "Prepare for production by migrating to Vertex AI in Firebase\n",
                        "description": "<p>\n  <i>Using the Google AI Swift SDK to call the Gemini API directly from\n  a mobile client is only for prototyping and experimentation.</i>\n  When you start to seriously develop your app beyong prototyping (especially as\n  you prepare for production), transition to use Vertex AI in Firebase and its\n  SDK for Apple platforms.\n</p> <p>\n  <b>For calling the Gemini API directly from your Swift app, we strongly\n  recommend using the Vertex AI in Firebase client SDK for Apple platforms.</b>\n  This SDK offers enhanced security features for mobile apps, including\n  Firebase App Check to help protect your app from unauthorized client access.\n  When you use this SDK, you can include large media files in your requests by\n  using Cloud Storage for Firebase.\n  Vertex AI in Firebase also integrates with other products in Google's Firebase\n  developer platform (like Cloud Firestore and Firebase Remote Config), while also\n  giving you streamlined access to the tools, workflows, and scale offered through\n  Google Cloud.\n  <a\n    href=\"https://cloud.google.com/vertex-ai/generative-ai/docs/migrate/migrate-google-ai#google-ai\"\n    data-label=\"path: https://cloud.google.com/vertex-ai/generative-ai/docs/migrate/migrate-google-ai\"\n    data-category=\"devsite-playlist: content link\"\n    class=\"gc-analytics-event\"\n    >Among other differences</a\n  >\n  , Vertex AI also supports increased request quotas and enterprise features.\n</p> <p>\n  Follow this guide to migrate to the Vertex AI in Firebase client SDK by updating\n  your package dependencies and imports, as well as changing how the AI model is\n  initialized.\n</p>\n",
                        "page": {}
                    },
                    {
                        "url": "https://developers.google.com/learn/pathways/quizzes/solution-ai-gemini-getting-started-swift",
                        "title": "Quiz",
                        "description": "Test your knowledge and earn your 'Getting started with Gemini and Swift' badge.",
                        "quiz": {
                            "badge": {
                                "title": "Getting started with the Gemini API and Swift",
                                "description": "Completed the 'Getting started with the Gemini API and Swift' learning pathway and quiz\n",
                                "imageUrl": "/static/profile/badges/playlists/solutions/ai-gemini-getting-started-swift/badge.svg",
                                "sharing": {
                                    "title": "Achievement unlocked! I learned about getting started with the Gemini API and Swift. Check it out! #DevBadges",
                                    "description": "Earn this badge when you complete the 'Getting started with the Gemini API and Swift' learning pathway and quiz.",
                                    "imageUrl": "/static/profile/badges/playlists/solutions/ai-gemini-getting-started-swift/share.png",
                                    "imagePath": "developers.google.com/static/profile/badges/playlists/solutions/ai-gemini-getting-started-swift/share.png"
                                },
                                "url": "https://developers.google.com/profile/badges/playlists/solutions/ai-gemini-getting-started-swift",
                                "imagePath": "developers.google.com/static/profile/badges/playlists/solutions/ai-gemini-getting-started-swift/badge.svg"
                            }
                        }
                    }
                ]
            }
        },
        {
            "url": "https://developers.google.com/learn/pathways/solution-ai-gemini-getting-started-web",
            "title": "Getting started with the Gemini API and Web apps\n",
            "description": "Learn how to use the Gemini API and the Google AI JavaScript SDK to prototype generative AI for web apps. Use the Google AI JavaScript SDK to make your first generative AI call using the Gemini API in your client-side web application. Explore a sample application and learn how to make multimodal prompts (that combine image and text).\n",
            "playlist": {
                "learningActivities": [
                    {
                        "url": "https://developers.google.com/learn/pathways/solution-ai-gemini-101",
                        "title": "Introduction to the Gemini API and prompt engineering\n",
                        "description": "<p>\n  Explore Google AI Studio and the capabilities of the Gemini generative AI\n  model. Learn how to design and test the different types of prompts (freeform,\n  structured, and chat), get an API key, and build a simple NodeJS application.\n</p> <p>\n  This pathway is useful for further experimentation with Gemini and lays the\n  groundwork for integrating its features into a web application. Optionally,\n  you can also try out the Gemini API using a simple NodeJS web application.\n  Feel free to skip this step and return back to client-side web development in\n  this pathway.\n</p> <p>\n  Note that <b>calling the Gemini API directly from your web app using\n  the Google AI JavaScript SDK is only for <i>prototyping</i></b> and exploring\n  the Gemini generative AI models. For use cases beyond prototyping\n  (especially production or enterprise-scale apps), use\n  <a\n    href=\"https://firebase.google.com/docs/vertex-ai\"\n    data-label=\"path: https://firebase.google.com/docs/vertex-ai\"\n    data-category=\"devsite-playlist: content link\"\n    class=\"gc-analytics-event\">\n    Vertex AI in Firebase\n  </a>\n  instead.</b> It offers an SDK for Web that has additional security features,\n  support for large media file uploads, and streamlined integrations into the\n  Firebase and Google Cloud ecosystem. Alternatively, you can use the\n  Google AI JavaScript SDK to access the Gemini models server-side.\n</p>\n",
                        "playlist": {}
                    },
                    {
                        "url": "https://developers.google.com/idx/guides/build-gemini-api-app",
                        "title": "Try out the Gemini API template on Project IDX\n",
                        "description": "<p>\n  Try out the Gemini API template in Project IDX to quickly get started and\n  experiment with a JavaScript-based web app that uses generative AI. The\n  template contains a fully functioning app for you to quickly prototype with\n  the Gemini API on the web.\n</p> <p>\n  <a\n    href=\"https://developers.google.com/idx\"\n    data-label=\"path: https://developers.google.com/idx\"\n    data-category=\"devsite-playlist: content link\"\n    class=\"gc-analytics-event\"\n    >Project IDX</a\n  >\n  is an experimental, web-based integrated development environment. It supports\n  a variety of frameworks, including development for both web and cross-platform\n  applications. It is currently available in\n  <a\n    href=\"https://idx.dev/\"\n    data-label=\"path: https://idx.dev/\"\n    data-category=\"devsite-playlist: content link\"\n    class=\"gc-analytics-event external\"\n    >Public Preview</a\n  >.\n</p> <p>\n  The template uses the Vite framework to build a web app that makes multimodal\n  prompts to the Gemini API using the Google AI SDK directly or using LangChain.\n</p> <p>\n  To get started, follow the steps to create a new workspace using the \"Gemini\n  API\" template. Select the \"JavaScript Web App\" environment and follow the\n  guide to add your Gemini API key and run the application.\n</p>\n",
                        "page": {}
                    },
                    {
                        "url": "https://ai.google.dev/gemini-api/docs/quickstart",
                        "title": "Introduction to the Google AI JavaScript SDK\n",
                        "description": "<p>\n  The Google AI JavaScript SDK enables you to build your generative AI\n  integration with the\n  <a\n    href=\"https://ai.google.dev/gemini-api/docs\"\n    data-label=\"path: https://ai.google.dev/gemini-api/docs\"\n    data-category=\"devsite-playlist: content link\"\n    class=\"gc-analytics-event\"\n    >Google AI Gemini API</a\n  >.\n</p> <p>\n  <b>When calling the Gemini API directly from your mobile or web app, the\n  Google AI JavaScript SDK is only for <i>prototyping</i>.</b>\n  There are\n    <a\n      href=\"https://ai.google.dev/gemini-api/docs/api-key#security\"\n      data-label=\"path: https://ai.google.dev/gemini-api/docs/api-key#security\"\n      data-category=\"devsite-playlist: content link\"\n      class=\"gc-analytics-event\"\n      >additional security considerations</a\n    >\n  for using the Gemini API key in your web client applications since\n  you're risking exposing this API key to malicious actors if it's embedded or\n  retrieved by your client application. So, for use cases beyond\n  prototyping (especially production and enterprise-scale apps),\n    <a\n      href=\"https://firebase.google.com/docs/vertex-ai/migrate-to-vertex-ai?platform=web\"\n      data-label=\"path: https://firebase.google.com/docs/vertex-ai/migrate-to-vertex-ai?platform=web\"\n      data-category=\"devsite-playlist: content link\"\n      class=\"gc-analytics-event\"\n      >migrate to Vertex AI in Firebase</a\n    >\n  to call the Gemini API directly from your client app. Alternatively, you can access the\n  Gemini models server-side using either the Google AI JavaScript SDK or through\n    <a\n      href=\"https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/overview\"\n      data-label=\"path: https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/overview\"\n      data-category=\"devsite-playlist: content link\"\n      class=\"gc-analytics-event\"\n      >Vertex AI</a\n    >.\n</p> <p>\n  To get started with the Google AI JavaScript SDK, set up a project in\n  Google AI Studio, which includes obtaining an API key for the Gemini API.\n  Next, add the required dependency for the SDK to your build configuration or\n  import it directly using <code translate=\"no\" dir=\"ltr\">@google/generative-ai</code>. Then, you can\n  initialize the library with your API key and make your first API call.\n</p>\n",
                        "page": {}
                    },
                    {
                        "url": "https://github.com/google/generative-ai-js/tree/main/samples/web",
                        "title": "Explore the JavaScript sample app\n",
                        "description": "<p>\n  Explore more advanced use cases for the Google AI JavaScript SDK with the\n  sample app on GitHub.\n</p> <p>\n  This example app demonstrates three key use cases in more detail:\n  <a\n    href=\"https://github.com/google/generative-ai-js/blob/main/samples/web/index.html\"\n    data-label=\"path: https://github.com/google/generative-ai-js/blob/main/samples/web/index.html\"\n    data-category=\"devsite-playlist: content link\"\n    class=\"gc-analytics-event external\"\n    >generating text, photo reasoning (using multimodal inputs)</a\n  >, and\n  <a\n    href=\"https://github.com/google/generative-ai-js/blob/main/samples/web/chat.html\"\n    data-label=\"path: https://github.com/google/generative-ai-js/blob/main/samples/web/chat.html\"\n    data-category=\"devsite-playlist: content link\"\n    class=\"gc-analytics-event external\"\n    >multi-turn conversations (chat)</a\n  >. It also shows how to use\n  <a\n    href=\"https://ai.google.dev/api/generate-content#text_gen_text_only_prompt_streaming-JAVASCRIPT\"\n    data-label=\"path: https://ai.google.dev/api/generate-content#text_gen_text_only_prompt_streaming-JAVASCRIPT\"\n    data-category=\"devsite-playlist: content link\"\n    class=\"gc-analytics-event\"\n    >content streaming</a\n  >\n  to improve response time by displaying partial results.\n</p> <p>\n  Follow the steps in the <code translate=\"no\" dir=\"ltr\">README</code> to get started, which includes\n  configuring your Gemini API key and providing it to the HTTP server\n  included in this sample app.\n</p>\n",
                        "page": {}
                    },
                    {
                        "url": "https://ai.google.dev/gemini-api/docs/file-prompting-strategies",
                        "title": "Multimodal prompting using the Google AI Javascript SDK\n",
                        "description": "<p>\n  Multimodal prompts combine different types of media together, such as text,\n  images, and audio. For example, you could create prompts that identify objects\n  in an image, extract text from a photo, or reference a picture.\n</p> <p>\n  To get started, read this guide about file prompting strategies and multimodal\n  concepts, which includes best practices for designing multimodal prompts.\n</p> <p>\n  Next, explore the multimodal capabilities of the Gemini models in\n  <a\n    href=\"https://aistudio.google.com/\"\n    data-label=\"path: https://aistudio.google.com/\"\n    data-category=\"devsite-playlist: content link\"\n    class=\"gc-analytics-event external\"\n    >Google AI Studio</a\n  >\n  by uploading or selecting a file as part of your prompt.\n</p> <p>\n  <a\n    href=\"https://ai.google.dev/api/generate-content#text_gen_multimodal_one_image_prompt-JAVASCRIPT\"\n    data-label=\"path: https://ai.google.dev/api/generate-content#text_gen_multimodal_one_image_prompt-JAVASCRIPT\"\n    data-category=\"devsite-playlist: content link\"\n    class=\"gc-analytics-event\"\n  >\n    Learn how to use multimodal inputs\n  </a>\n  using the Google AI JavaScript SDK, find\n  <a\n    href=\"https://ai.google.dev/gemini-api/docs/vision#prompting-images\"\n    data-label=\"path: https://ai.google.dev/gemini-api/docs/vision#prompting-images\"\n    data-category=\"devsite-playlist: content link\"\n    class=\"gc-analytics-event\"\n  >\n    image requirements for prompts\n  </a>\n  for prompts, and explore the\n  <a\n    href=\"https://github.com/google/generative-ai-js/blob/main/samples/web/index.html\"\n    data-label=\"path: https://github.com/google/generative-ai-js/blob/main/samples/web/index.html\"\n    data-category=\"devsite-playlist: content link\"\n    class=\"gc-analytics-event external\"\n    >multimodal image reasoning demo in the sample app </a\n  >.\n</p> <p>\n  For further reading, see the solution\n  <a\n    href=\"https://developers.google.com/learn/pathways/solution-ai-gemini-images\"\n    class=\"gc-analytics-event\"\n    data-label=\"path: https://developers.google.com/learn/pathways/solution-ai-gemini-images\"\n    data-category=\"devsite-playlist: content link\"\n    >Leveraging the Gemini Pro Vision model for image understanding, multimodal\n    prompts and accessibility</a\n  >.\n</p>\n",
                        "page": {}
                    },
                    {
                        "url": "https://firebase.google.com/docs/vertex-ai/migrate-to-vertex-ai",
                        "title": "Prepare for production by migrating to Vertex AI in Firebase\n",
                        "description": "<p>\n  <i>Using the Google AI JavaScript SDK to call the Gemini API directly\n  from a web client is only for prototyping and experimentation.</i>\n  When you start to seriously develop your app beyong prototyping (especially as\n  you prepare for production), transition to use Vertex AI in Firebase and its\n  SDK for Web.\n</p> <p>\n  <b>For calling the Gemini API directly from your web app, we strongly\n  recommend using the Vertex AI in Firebase client SDK for Web.</b>\n  This SDK offers enhanced security features for web apps, including\n  Firebase App Check to help protect your app from unauthorized client access.\n  When you use this SDK, you can include large media files in your requests by\n  using Cloud Storage for Firebase.\n  Vertex AI in Firebase also integrates with other products in Google's Firebase\n  developer platform (like Cloud Firestore and Firebase Remote Config), while also\n  giving you streamlined access to the tools, workflows, and scale offered through\n  Google Cloud.\n  <a\n    href=\"https://cloud.google.com/vertex-ai/generative-ai/docs/migrate/migrate-google-ai#google-ai\"\n    data-label=\"path: https://cloud.google.com/vertex-ai/generative-ai/docs/migrate/migrate-google-ai\"\n    data-category=\"devsite-playlist: content link\"\n    class=\"gc-analytics-event\"\n    >Among other differences</a\n  >\n  , Vertex AI also supports increased request quotas and enterprise features.\n</p> <p>\n  Follow this guide to migrate to the Vertex AI in Firebase client SDK by\n  updating your package dependencies, imports, and changing how the AI model is\n  initialized.\n</p>\n",
                        "page": {}
                    },
                    {
                        "url": "https://developers.google.com/learn/pathways/quizzes/solution-ai-gemini-getting-started-web",
                        "title": "Quiz",
                        "description": "Test your knowledge and earn your 'Getting started with the Gemini API and Web Apps' badge.",
                        "quiz": {
                            "badge": {
                                "title": "Getting started with the Gemini API and Web Apps",
                                "description": "Completed the 'Getting started with the Gemini API and Web Apps' learning pathway and quiz\n",
                                "imageUrl": "/static/profile/badges/playlists/solutions/ai-gemini-getting-started-web/badge.svg",
                                "sharing": {
                                    "title": "Achievement unlocked! I learned about getting started with the Gemini API and Web Apps. Check it out! #DevBadges",
                                    "description": "Earn this badge when you complete the 'Getting started with the Gemini API and Web Apps' learning pathway and quiz.",
                                    "imageUrl": "/static/profile/badges/playlists/solutions/ai-gemini-getting-started-web/share.png",
                                    "imagePath": "developers.google.com/static/profile/badges/playlists/solutions/ai-gemini-getting-started-web/share.png"
                                },
                                "url": "https://developers.google.com/profile/badges/playlists/solutions/ai-gemini-getting-started-web",
                                "imagePath": "developers.google.com/static/profile/badges/playlists/solutions/ai-gemini-getting-started-web/badge.svg"
                            }
                        }
                    }
                ]
            }
        },
        {
            "url": "https://web.dev/learn/accessibility",
            "title": "Learn Accessibility",
            "description": "An evergreen accessibility course and reference to level up your web development.",
            "playlist": {
                "learningActivities": [
                    {
                        "url": "https://web.dev/learn/accessibility/welcome",
                        "title": "Welcome to Learn Accessibility!",
                        "description": "An evergreen accessibility course and reference to level up your web development.",
                        "page": {}
                    },
                    {
                        "url": "https://web.dev/learn/accessibility/why",
                        "title": "What is digital accessibility, and why does it matter?",
                        "description": "Design and build websites and web apps so that disabled people can interact in a meaningful and equivalent way. Read about the business and legal impact of these choices.\n",
                        "page": {}
                    },
                    {
                        "url": "https://web.dev/learn/accessibility/measure",
                        "title": "How is digital accessibility measured?",
                        "description": "Introduction to accessibility measurement, which ensures everyone, including people with disabilities, can still interact with your website in a meaningful and equal way.\n",
                        "page": {}
                    },
                    {
                        "url": "https://web.dev/learn/accessibility/aria-html",
                        "title": "ARIA and HTML",
                        "description": "When to use ARIA versus HTML.",
                        "page": {}
                    },
                    {
                        "url": "https://web.dev/learn/accessibility/structure",
                        "title": "Content structure",
                        "description": "Use semantic HTML, landmarks, and tables for accessible content.\n",
                        "page": {}
                    },
                    {
                        "url": "https://web.dev/learn/accessibility/more-html",
                        "title": "The Document",
                        "description": "Additional HTML elements to consider when building accessible websites and web apps.\n",
                        "page": {}
                    },
                    {
                        "url": "https://web.dev/learn/accessibility/focus",
                        "title": "Keyboard focus",
                        "description": "Understand and enhance keyboard navigation order and style.\n",
                        "page": {}
                    },
                    {
                        "url": "https://web.dev/learn/accessibility/javascript",
                        "title": "JavaScript",
                        "description": "Write accessible trigger events, page titles, dynamic content, and more.\n",
                        "page": {}
                    },
                    {
                        "url": "https://web.dev/learn/accessibility/images",
                        "title": "Images",
                        "description": "Create accessible images.",
                        "page": {}
                    },
                    {
                        "url": "https://web.dev/learn/accessibility/color-contrast",
                        "title": "Color and contrast",
                        "description": "Build accessible color palettes with appropriate contrast.\n",
                        "page": {}
                    },
                    {
                        "url": "https://web.dev/learn/accessibility/motion",
                        "title": "Animation and motion",
                        "description": "Support people with all types of movement-triggered disorders.\n",
                        "page": {}
                    },
                    {
                        "url": "https://web.dev/learn/accessibility/typography",
                        "title": "Typography",
                        "description": "Pick the right typefaces, font sizes, and structure your copy with an accessible layout.\n",
                        "page": {}
                    },
                    {
                        "url": "https://web.dev/learn/accessibility/video-audio",
                        "title": "Video and audio",
                        "description": "Alternative media types which make your video and audio accessible.\n",
                        "page": {}
                    },
                    {
                        "url": "https://web.dev/learn/accessibility/forms",
                        "title": "Forms",
                        "description": "Create accessible forms.",
                        "page": {}
                    },
                    {
                        "url": "https://web.dev/learn/accessibility/patterns",
                        "title": "Patterns, components, and design systems",
                        "description": "Evaluate patterns, components, and design systems for accessibility.",
                        "page": {}
                    },
                    {
                        "url": "https://web.dev/learn/accessibility/design-ux",
                        "title": "Design and user experience",
                        "description": "Create accessible designs and evaluate your user's experience.",
                        "page": {}
                    },
                    {
                        "url": "https://web.dev/learn/accessibility/test-automated",
                        "title": "Automated accessibility testing",
                        "description": "How to perform automated accessibility testing.",
                        "page": {}
                    },
                    {
                        "url": "https://web.dev/learn/accessibility/test-manual",
                        "title": "Manual accessibility testing",
                        "description": "How to manually test for accessibility.",
                        "page": {}
                    },
                    {
                        "url": "https://web.dev/learn/accessibility/test-assistive-technology",
                        "title": "Assistive Technology testing",
                        "description": "How to test with Assistive Technology (AT).",
                        "page": {}
                    },
                    {
                        "url": "https://web.dev/learn/accessibility/conclusion",
                        "title": "Conclusion and next steps",
                        "description": "Further resources to help you take your next steps.",
                        "page": {}
                    },
                    {
                        "url": "https://web.dev/learn/accessibility/glossary",
                        "title": "Glossary",
                        "description": "Learn common accessibility terms and concepts.",
                        "page": {}
                    }
                ]
            }
        },
        {
            "url": "https://web.dev/learn/design",
            "title": "Learn Responsive Design",
            "description": "A course exploring all aspects of responsive design. Learn how to make sites that look great and work well for everyone.",
            "playlist": {
                "learningActivities": [
                    {
                        "url": "https://web.dev/learn/design/welcome",
                        "title": "Welcome to Learn Responsive Design!",
                        "description": "A course exploring all aspects of responsive design. Learn how to make sites that look great and work well for everyone.",
                        "page": {}
                    },
                    {
                        "url": "https://web.dev/learn/design/intro",
                        "title": "Introduction",
                        "description": "Find out where responsive design came from.",
                        "page": {}
                    },
                    {
                        "url": "https://web.dev/learn/design/media-queries",
                        "title": "Media queries",
                        "description": "Adapt your designs to different screen sizes using CSS media queries.",
                        "page": {}
                    },
                    {
                        "url": "https://web.dev/learn/design/internationalization",
                        "title": "Internationalization",
                        "description": "Prepare your designs for different languages and writing modes.",
                        "page": {}
                    },
                    {
                        "url": "https://web.dev/learn/design/macro-layouts",
                        "title": "Macro layouts",
                        "description": "Design page layouts using a choice of CSS techniques.",
                        "page": {}
                    },
                    {
                        "url": "https://web.dev/learn/design/micro-layouts",
                        "title": "Micro layouts",
                        "description": "Build flexible components that can be placed anywhere.",
                        "page": {}
                    },
                    {
                        "url": "https://web.dev/learn/design/typography",
                        "title": "Typography",
                        "description": "Make your text legible and beautiful, no matter where it appears.",
                        "page": {}
                    },
                    {
                        "url": "https://web.dev/learn/design/responsive-images",
                        "title": "Responsive images",
                        "description": "Give your visitors the most appropriate images for their devices and screens.",
                        "page": {}
                    },
                    {
                        "url": "https://web.dev/learn/design/picture-element",
                        "title": "The picture element",
                        "description": "Exercise more creative control over your images.",
                        "page": {}
                    },
                    {
                        "url": "https://web.dev/learn/design/icons",
                        "title": "Icons",
                        "description": "Use SVG for scalable responsive iconography.",
                        "page": {}
                    },
                    {
                        "url": "https://web.dev/learn/design/theming",
                        "title": "Theming",
                        "description": "Adapt your designs to match user preferences such as a dark mode.",
                        "page": {}
                    },
                    {
                        "url": "https://web.dev/learn/design/accessibility",
                        "title": "Accessibility",
                        "description": "Ensure that your website is available to everyone.",
                        "page": {}
                    },
                    {
                        "url": "https://web.dev/learn/design/interaction",
                        "title": "Interaction",
                        "description": "Prepare your pages for different input mechanisms; mouse, keyboard, and touch.",
                        "page": {}
                    },
                    {
                        "url": "https://web.dev/learn/design/ui-patterns",
                        "title": "User interface patterns",
                        "description": "Consider some common UI elements that adapt to different screen sizes.",
                        "page": {}
                    },
                    {
                        "url": "https://web.dev/learn/design/media-features",
                        "title": "Media features",
                        "description": "A round-up of all the ways that media features let you respond to devices and preferences.",
                        "page": {}
                    },
                    {
                        "url": "https://web.dev/learn/design/screen-configurations",
                        "title": "Screen configurations",
                        "description": "Prepare your content for devices with multiple screens.",
                        "page": {}
                    },
                    {
                        "url": "https://web.dev/learn/design/conclusion",
                        "title": "Conclusion and next steps",
                        "description": "Further resources to help you take your next steps.",
                        "page": {}
                    }
                ]
            }
        },
        {
            "url": "https://web.dev/learn/forms",
            "title": "Learn Forms",
            "description": "A course about HTML forms to help you improve your web developer expertise.",
            "playlist": {
                "learningActivities": [
                    {
                        "url": "https://web.dev/learn/forms/welcome",
                        "title": "Welcome to Learn Forms!",
                        "description": "A course about HTML forms to help you improve your web developer expertise.",
                        "page": {}
                    },
                    {
                        "url": "https://web.dev/learn/forms/form-element",
                        "title": "Use forms to get data from users",
                        "description": "Learn the basics of using a form on the web with this introduction to the form element.",
                        "page": {}
                    },
                    {
                        "url": "https://web.dev/learn/forms/form-fields",
                        "title": "Help users enter data in forms",
                        "description": "An overview of the various form elements you can choose from to build your form.",
                        "page": {}
                    },
                    {
                        "url": "https://web.dev/learn/forms/auto",
                        "title": "Help users avoid re-entering data in forms",
                        "description": "Make it more convenient for users to fill out forms.",
                        "page": {}
                    },
                    {
                        "url": "https://web.dev/learn/forms/validation",
                        "title": "Help users enter the right data in forms",
                        "description": "Learn how to validate your forms on the frontend.",
                        "page": {}
                    },
                    {
                        "url": "https://web.dev/learn/forms/testing",
                        "title": "Test your forms",
                        "description": "Learn how to test and analyze your forms.",
                        "page": {}
                    },
                    {
                        "url": "https://web.dev/learn/forms/design-basics",
                        "title": "Design basics",
                        "description": "Learn how to build user-friendly forms.",
                        "page": {}
                    },
                    {
                        "url": "https://web.dev/learn/forms/accessibility",
                        "title": "Accessibility",
                        "description": "How to build inclusive forms.",
                        "page": {}
                    },
                    {
                        "url": "https://web.dev/learn/forms/internationalization",
                        "title": "Internationalization and localization",
                        "description": "Be prepared for international data formats, and learn how to plan your form for localization.",
                        "page": {}
                    },
                    {
                        "url": "https://web.dev/learn/forms/security-privacy",
                        "title": "Security and privacy",
                        "description": "Learn how to make your forms secure and keep your users' data private.",
                        "page": {}
                    },
                    {
                        "url": "https://web.dev/learn/forms/autofill",
                        "title": "Autofill",
                        "description": "Learn all about autofill and the autocomplete attribute.",
                        "page": {}
                    },
                    {
                        "url": "https://web.dev/learn/forms/usability-testing",
                        "title": "How to test forms for usability",
                        "description": "Discover how to do usability testing and ensure your form works well for all your users.",
                        "page": {}
                    },
                    {
                        "url": "https://web.dev/learn/forms/cross-platform-testing",
                        "title": "Test forms across devices and platforms",
                        "description": "Ensure your form works with different devices, browsers, platforms, and different contexts.",
                        "page": {}
                    },
                    {
                        "url": "https://web.dev/learn/forms/data",
                        "title": "Gathering data",
                        "description": "Learn how to measure and analyze your form.",
                        "page": {}
                    },
                    {
                        "url": "https://web.dev/learn/forms/form",
                        "title": "The form element in depth",
                        "description": "Learn all about the form element, when you should use a form, and how a form works in detail.",
                        "page": {}
                    },
                    {
                        "url": "https://web.dev/learn/forms/fields",
                        "title": "Form fields in depth",
                        "description": "Learn about the different form fields you can use, and how to choose the right form element.",
                        "page": {}
                    },
                    {
                        "url": "https://web.dev/learn/forms/attributes",
                        "title": "Form attributes in depth",
                        "description": "Learn all about form attributes, how to modify the layout of on-screen keyboards, activate built-in validation, and more.",
                        "page": {}
                    },
                    {
                        "url": "https://web.dev/learn/forms/styling",
                        "title": "Styling forms",
                        "description": "Style forms using CSS, while ensuring they remain usable and readable for everyone.",
                        "page": {}
                    },
                    {
                        "url": "https://web.dev/learn/forms/styling-form-controls",
                        "title": "Styling form controls",
                        "description": "Learn how to implement form controls with CSS.",
                        "page": {}
                    },
                    {
                        "url": "https://web.dev/learn/forms/javascript",
                        "title": "JavaScript",
                        "description": "Find out how to use JavaScript to enhance your forms.",
                        "page": {}
                    },
                    {
                        "url": "https://web.dev/learn/forms/identity",
                        "title": "Identity",
                        "description": "Find out how to set up your forms using best practices for user authentication.",
                        "page": {}
                    },
                    {
                        "url": "https://web.dev/learn/forms/payment",
                        "title": "Payment forms",
                        "description": "Improve conversion rates by building better payment forms.",
                        "page": {}
                    },
                    {
                        "url": "https://web.dev/learn/forms/address",
                        "title": "Address forms",
                        "description": "Help users fill out address forms quickly and easily.",
                        "page": {}
                    },
                    {
                        "url": "https://web.dev/learn/forms/conclusion",
                        "title": "Conclusion and next steps",
                        "description": "Further resources to help you take your next steps.",
                        "page": {}
                    }
                ]
            }
        },
        {
            "url": "https://web.dev/learn/html",
            "title": "Learn HTML",
            "description": "This HTML course for web developers provides a solid overview for developers, from novice to expert level HTML.",
            "playlist": {
                "learningActivities": [
                    {
                        "url": "https://web.dev/learn/html/welcome",
                        "title": "Welcome to Learn HTML!",
                        "description": "This HTML course for web developers provides a solid overview for developers, from novice to expert level HTML.",
                        "page": {}
                    },
                    {
                        "url": "https://web.dev/learn/html/overview",
                        "title": "Overview of HTML",
                        "description": "A brief introduction to the key concepts in HTML.",
                        "page": {}
                    },
                    {
                        "url": "https://web.dev/learn/html/document-structure",
                        "title": "Document structure",
                        "description": "Learn how to structure your HTML documents with a solid foundation.",
                        "page": {}
                    },
                    {
                        "url": "https://web.dev/learn/html/metadata",
                        "title": "Metadata",
                        "description": "How to use meta tags to provide information about your documents.",
                        "page": {}
                    },
                    {
                        "url": "https://web.dev/learn/html/semantic-html",
                        "title": "Semantic HTML",
                        "description": "Using the correct HTML elements to describe your document content.",
                        "page": {}
                    },
                    {
                        "url": "https://web.dev/learn/html/headings-and-sections",
                        "title": "Headings and sections",
                        "description": "How to correctly use sectioning elements to give meaning to your content.",
                        "page": {}
                    },
                    {
                        "url": "https://web.dev/learn/html/attributes",
                        "title": "Attributes",
                        "description": "Learn about the different global attributes along with attributes specific to particular HTML elements.",
                        "page": {}
                    },
                    {
                        "url": "https://web.dev/learn/html/text-basics",
                        "title": "Text basics",
                        "description": "How to format text using HTML.",
                        "page": {}
                    },
                    {
                        "url": "https://web.dev/learn/html/links",
                        "title": "Links",
                        "description": "Everything you need to know about links.",
                        "page": {}
                    },
                    {
                        "url": "https://web.dev/learn/html/lists",
                        "title": "Lists",
                        "description": "Lists and other ways of grouping your content.",
                        "page": {}
                    },
                    {
                        "url": "https://web.dev/learn/html/navigation",
                        "title": "Navigation",
                        "description": "Navigation is a key element of any site of application, and it starts with HTML.",
                        "page": {}
                    },
                    {
                        "url": "https://web.dev/learn/html/tables",
                        "title": "Tables",
                        "description": "Understanding how to use tables to mark up tabular data.",
                        "page": {}
                    },
                    {
                        "url": "https://web.dev/learn/html/forms",
                        "title": "Forms",
                        "description": "An overview of forms in HTML.",
                        "page": {}
                    },
                    {
                        "url": "https://web.dev/learn/html/images",
                        "title": "Images",
                        "description": "An overview of images in HTML.",
                        "page": {}
                    },
                    {
                        "url": "https://web.dev/learn/html/audio-video",
                        "title": "Audio and Video",
                        "description": "Discover how to work with HTML media such as audio and video.",
                        "page": {}
                    },
                    {
                        "url": "https://web.dev/learn/html/template",
                        "title": "Template, slot, and shadow",
                        "description": "An explanation of template, slot, and shadow.",
                        "page": {}
                    },
                    {
                        "url": "https://web.dev/learn/html/apis",
                        "title": "HTML APIs",
                        "description": "Learn how HTML information can be exposed and manipulated using JavaScript.",
                        "page": {}
                    },
                    {
                        "url": "https://web.dev/learn/html/focus",
                        "title": "Focus",
                        "description": "How to manage focus order in your HTML documents.",
                        "page": {}
                    },
                    {
                        "url": "https://web.dev/learn/html/inline-text",
                        "title": "Other inline text elements",
                        "description": "An introduction to the range of elements used to mark-up text.",
                        "page": {}
                    },
                    {
                        "url": "https://web.dev/learn/html/details",
                        "title": "Details and summary",
                        "description": "Discover how the very useful details and summary elements work, and where to use them.",
                        "page": {}
                    },
                    {
                        "url": "https://web.dev/learn/html/dialog",
                        "title": "Dialog",
                        "description": "The <dialog> element is useful for representing any kind of dialog in HTML. Find out how it works.",
                        "page": {}
                    },
                    {
                        "url": "https://web.dev/learn/html/conclusion",
                        "title": "Conclusion and next steps",
                        "description": "Wrapping up with some further resources.",
                        "page": {}
                    }
                ]
            }
        },
        {
            "url": "https://web.dev/learn/testing",
            "title": "Learn Testing",
            "description": "An in-depth course on software testing.",
            "playlist": {
                "learningActivities": [
                    {
                        "url": "https://web.dev/learn/testing/welcome",
                        "title": "Welcome to Learn Testing!",
                        "description": "An in-depth course on software testing.",
                        "page": {}
                    },
                    {
                        "url": "https://web.dev/learn/testing/get-started/what-testing-is",
                        "title": "What testing is",
                        "description": "A high-level introduction to testing.",
                        "page": {}
                    },
                    {
                        "url": "https://web.dev/learn/testing/get-started/where-tests-run",
                        "title": "Where tests run",
                        "description": "Learn how to run tests manually or as part of an automated process.",
                        "page": {}
                    },
                    {
                        "url": "https://web.dev/learn/testing/get-started/testing-environment",
                        "title": "The testing environment",
                        "description": "Learn to use runtime tools for testing, as well as specialized frameworks for testing code in browsers.",
                        "page": {}
                    },
                    {
                        "url": "https://web.dev/learn/testing/get-started/test-types",
                        "title": "Types of automated testing",
                        "description": "Learn about common categorizations of test types.",
                        "page": {}
                    },
                    {
                        "url": "https://web.dev/learn/testing/get-started/what-to-test",
                        "title": "What to test and your approach",
                        "description": "Learn how to assess your code for testing.",
                        "page": {}
                    },
                    {
                        "url": "https://web.dev/learn/testing/get-started/component-testing",
                        "title": "Component testing in practice",
                        "description": "Examples of test design for a React component with complex dependencies.",
                        "page": {}
                    },
                    {
                        "url": "https://web.dev/learn/testing/get-started/static-analysis",
                        "title": "Static analysis",
                        "description": "Learn to use linter tools for basic automated testing.",
                        "page": {}
                    },
                    {
                        "url": "https://web.dev/learn/testing/assertions/tools",
                        "title": "Tools of the trade",
                        "description": "Learn about assertions and other primitives common to most testing frameworks.",
                        "page": {}
                    },
                    {
                        "url": "https://web.dev/learn/testing/appendix",
                        "title": "Appendix",
                        "description": "Additional information that might be helpful on your test development journey.",
                        "page": {}
                    },
                    {
                        "url": "https://web.dev/learn/testing/coming-soon",
                        "title": "Coming Soon",
                        "description": "Stay tuned for more information about testing!",
                        "page": {}
                    }
                ]
            }
        }
    ],
  "faqs":[
      {
          "question": "What is GDSC RCCIIT?",
          "answer": "GDSC RCCIIT is a community of developers at RCC Institute of Information Technology that focuses on learning, building, and collaborating on various projects."
      },
      {
          "question": "How can I join GDSC RCCIIT?",
          "answer": "You can join GDSC RCCIIT by signing up through our official website or by attending our introductory sessions held at the beginning of the semester."
      },
      {
          "question": "What kind of events does GDSC RCCIIT organize?",
          "answer": "We organize workshops, hackathons, tech talks, and community projects to help members enhance their skills and build a strong network."
      },
      {
          "question": "Do I need to be an expert in coding to join?",
          "answer": "No, GDSC RCCIIT welcomes students of all skill levels. Our aim is to provide a supportive environment for everyone to learn and grow."
      },
      {
          "question": "How can I contribute to GDSC RCCIIT projects?",
          "answer": "You can contribute by participating in hackathons, collaborating on ongoing projects, or proposing your own ideas to the community."
      },
      {
          "question": "Are there any membership fees?",
          "answer": "No, joining GDSC RCCIIT is completely free. We aim to provide valuable learning opportunities without any financial barriers."
      }
  ],
  "posts":[
      {
          "id": 1,
          "title": "How to get started with Daneízo?",
          "content": "I'm new to the platform and would like to know how to begin."
      },
      {
          "id": 2,
          "title": "Best items to rent for a short trip?",
          "content": "Looking for suggestions on items to rent for a weekend trip."
      },
      {
          "id": 3,
          "title": "What is GDSC RCCIIT?",
          "content": "GDSC RCCIIT is a community for students at RCCIIT to learn about and grow their skills in technology and development."
      },
      {
          "id": 4,
          "title": "How can I join GDSC RCCIIT?",
          "content": "You can join GDSC RCCIIT by signing up on our official website or attending our introductory sessions."
      },
      {
          "id": 5,
          "title": "What events does GDSC RCCIIT organize?",
          "content": "We organize workshops, hackathons, and study jams to help students improve their technical skills and collaborate on projects."
      },
      {
          "id": 6,
          "title": "Who can join GDSC RCCIIT?",
          "content": "Any student from RCCIIT interested in learning and collaborating in the tech space can join GDSC."
      },
      {
          "id": 7,
          "title": "What technologies does GDSC focus on?",
          "content": "GDSC focuses on various technologies including web development, machine learning, cloud computing, and more."
      },
      {
          "id": 8,
          "title": "How does GDSC help students?",
          "content": "GDSC provides students with resources, mentorship, and opportunities to work on real-world projects."
      },
      {
          "id": 9,
          "title": "What are the benefits of joining GDSC?",
          "content": "Joining GDSC offers networking opportunities, skill development, and the chance to work on impactful projects."
      },
      {
          "id": 10,
          "title": "Can I propose an event for GDSC?",
          "content": "Yes, if you have a great idea for an event, you can propose it to the GDSC team for consideration."
      }
  ]
}
